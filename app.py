# Create an optimized version of the Streamlit app with performance improvements for many files.
# Key upgrades:
# - Cached, parallel file reading
# - Optional Polars backend (if installed)
# - Downcasting dtypes + categorical conversion
# - On-demand charts (to avoid rendering overhead)
# - Vectorized per-group stats via pandas agg
# - Heavier ops hidden behind expanders
# - Safer large-data display (sample/limit)

app_code = r'''
# -*- coding: utf-8 -*-
"""
ğŸ§ª Tetkik Analiz ArayÃ¼zÃ¼ â€” Ã‡oklu Dosya (Optimize)
- Ã‡oklu dosya iÃ§in hÄ±zlÄ± okuma (paralel + cache)
- Bellek optimizasyonu (downcast, categorical)
- Ä°steÄŸe baÄŸlÄ± Polars hÄ±zlandÄ±rma (kuruluysa)
- BÃ¼yÃ¼k tablolarÄ± temkinli gÃ¶sterim (Ã¶rnekleme/limit)
- Grafikler isteÄŸe baÄŸlÄ± oluÅŸturulur (butonlar/checkbox), matplotlib (renk set edilmez)
Kurulum:
    pip install streamlit pandas numpy scipy openpyxl matplotlib
(opsiyonel hÄ±zlandÄ±rma)
    pip install polars pyarrow
Ã‡alÄ±ÅŸtÄ±rma:
    streamlit run app_optimized.py
"""

import io
import math
import numpy as np
import pandas as pd
import streamlit as st
from scipy import stats
import matplotlib.pyplot as plt
from concurrent.futures import ThreadPoolExecutor

# ============== Ayarlar ============== #
st.set_page_config(page_title="Tetkik Analiz â€” Optimize", layout="wide")
REQ_COLS = ["PROTOKOL_NO", "TCKIMLIK_NO", "TETKIK_ISMI", "TEST_DEGERI", "CINSIYET"]
# Kategorik (metin) testler
# NOT: A0 HPLC bir % deÄŸerdir â†’ KATEGORIK DEÄÄ°L!
CATEGORICAL_TESTS = {"Kan Grubu/", "Anormal Hb/"}


# --- EriÅŸkin pozitiflik eÅŸikleri (TETKIK_ISMI anahtarlarÄ±) ---
THRESHOLDS = {
    # HbA2
    "HbA2 (%)": (">=", 3.5),
    "A2/":      (">=", 3.5),   # sizin isimlendirme
    # HbF
    "HbF (%)":  (">",  2.0),
    "F/":       (">",  2.0),
    # Varyant yÃ¼zdeleri
    "HbS (%)":  (">",  0.0),
    "HbC (%)":  (">",  0.0),
    "HbD (%)":  (">",  0.0),
    "HbE (%)":  (">",  0.0),
}

# Ä°steÄŸe baÄŸlÄ±: yalnÄ±zca >0 filtresini varsayÄ±lan aÃ§Ä±k yapmak istediÄŸin test adlarÄ±
GT_ZERO_DEFAULT = {
    "HbS (%)","HbC (%)","HbD (%)","HbE (%)","HbF (%)","HbA2 (%)","A2/","F/",
    "C/","D/","E/","S/"          # HPLC varyant pikleri
}


# >0 ise "pozitif" sayÄ±lacak varyant yÃ¼zdeleri (ihtiyacÄ±na gÃ¶re geniÅŸlet)
VARIANT_NUMERIC_TESTS = {
    "HbS (%)", "HbC (%)", "HbD (%)", "HbE (%)",
    "HbF (%)", "HbA2 (%)",   # eÅŸik kullanacaksan ayrÄ±ca ekleriz
    "Anormal Hb/"            # sayÄ± geliyorsa >0 filtre uygular
}
DISPLAY_LIMIT = 200  # BÃ¼yÃ¼k veri iÃ§in Ã¶nizleme limiti

# Polars mevcut mu?
try:
    import polars as pl
    HAS_POLARS = True
except Exception:
    HAS_POLARS = False

# ============== YardÄ±mcÄ±lar ============== #
def coerce_numeric(series: pd.Series) -> pd.Series:
    s = series.astype(str).str.replace(",", ".", regex=False).str.replace(" ", "", regex=False)
    return pd.to_numeric(s, errors="coerce")
    
# __VAL_NUM__ kolonunu gÃ¼venle oluÅŸturur (yoksa ekler)
def add_numeric_copy(frame, src_col="TEST_DEGERI", out_col="__VAL_NUM__"):
    if out_col not in frame.columns:
        tmp = (
            frame[src_col].astype(str)
            .str.replace(",", ".", regex=False)
            .str.replace(" ", "", regex=False)
        )
        frame[out_col] = pd.to_numeric(tmp, errors="coerce")
    return frame
    
def check_columns(df: pd.DataFrame):
    return [c for c in REQ_COLS if c not in df.columns]

def downcast_df(df: pd.DataFrame) -> pd.DataFrame:
    # PROTOKOL_NO, TCKIMLIK_NO sayÄ±ya dÃ¶nmesin (ID olabilir), diÄŸer uygun alanlarÄ± kÃ¼Ã§Ã¼lt
    # TEST_DEGERI numerik
    if "TEST_DEGERI" in df.columns:
        df["TEST_DEGERI"] = coerce_numeric(df["TEST_DEGERI"])
        df["TEST_DEGERI"] = pd.to_numeric(df["TEST_DEGERI"], errors="coerce", downcast="float")
    # Kategorik alanlar
    for col in ["TETKIK_ISMI", "CINSIYET", "SOURCE_FILE"]:
        if col in df.columns:
            df[col] = df[col].astype("category")
    return df

def descr_stats_fast(x: pd.Series) -> dict:
    x = pd.to_numeric(x, errors="coerce")
    x = x[~x.isna()]
    if x.empty:
        return {"count": 0, "mean": np.nan, "std": np.nan, "min": np.nan,
                "q1": np.nan, "median": np.nan, "q3": np.nan, "max": np.nan,
                "cv%": np.nan, "iqr": np.nan}
    q = np.percentile(x, [25, 50, 75])
    mean = float(x.mean())
    std = float(x.std(ddof=1)) if len(x) > 1 else 0.0
    cv = (std / mean) * 100 if mean != 0 else np.nan
    return {
        "count": int(x.size),
        "mean": mean,
        "std": std,
        "min": float(x.min()),
        "q1": float(q[0]),
        "median": float(q[1]),
        "q3": float(q[2]),
        "max": float(x.max()),
        "cv%": float(cv),
        "iqr": float(q[2] - q[0]),
    }

def normality_flag(x: pd.Series, alpha=0.05) -> str:
    x = pd.to_numeric(x, errors="coerce").dropna()
    if len(x) < 3:
        return "yetersiz"
    try:
        if len(x) <= 5000:
            stat, p = stats.shapiro(x)
            return "normal" if p >= alpha else "non-normal"
        else:
            res = stats.anderson(x, dist="norm")
            crit = res.critical_values[2]  # 5%
            return "normal" if res.statistic < crit else "non-normal"
    except Exception:
        return "bilinmiyor"
        
def add_numeric_copy(frame, src_col="TEST_DEGERI", out_col="__VAL_NUM__"):
    if out_col not in frame.columns:
        tmp = (frame[src_col].astype(str)
               .str.replace(",", ".", regex=False)
               .str.replace(" ", "", regex=False))
        frame[out_col] = pd.to_numeric(tmp, errors="coerce")
    return frame

def apply_threshold(series, rule):
    op, cut = rule
    if op == ">=": return series >= cut
    if op == ">":  return series >  cut
    if op == "<=": return series <= cut
    if op == "<":  return series <  cut
    return series.notna()
    
def nonparametric_test_by_group(df, val_col, grp_col):
    # Gruplar
    groups = [g.dropna() for _, g in df.groupby(grp_col)[val_col]]
    groups = [pd.to_numeric(g, errors="coerce").dropna() for g in groups]
    groups = [g for g in groups if len(g) > 0]
    unique_groups = df[grp_col].dropna().unique()
    unique_groups = [g for g in unique_groups if df[df[grp_col] == g][val_col].notna().sum() > 0]

    if len(unique_groups) < 2:
        return "KarÅŸÄ±laÅŸtÄ±rma iÃ§in en az 2 grup gerekli.", None

    if len(unique_groups) == 2:
        gnames = list(unique_groups)
        x = pd.to_numeric(df[df[grp_col] == gnames[0]][val_col], errors="coerce").dropna()
        y = pd.to_numeric(df[df[grp_col] == gnames[1]][val_col], errors="coerce").dropna()
        if len(x) >= 1 and len(y) >= 1:
            stat, p = stats.mannwhitneyu(x, y, alternative="two-sided")
            return f"Mannâ€“Whitney U: U={stat:.2f}, p={p:.4g} ({gnames[0]} vs {gnames[1]})", ("MWU", stat, p, gnames[0], gnames[1])
        else:
            return "Gruplarda yeterli gÃ¶zlem yok.", None
    else:
        stat, p = stats.kruskal(*groups)
        return f"Kruskalâ€“Wallis: H={stat:.2f}, p={p:.4g} (grup sayÄ±sÄ±: {len(unique_groups)})", ("KW", stat, p, unique_groups)

def make_boxplot(df, x_col, y_col, title="Kutu GrafiÄŸi"):
    valid = df[[x_col, y_col]].copy()
    valid[y_col] = pd.to_numeric(valid[y_col], errors="coerce")
    valid = valid.dropna()
    if valid.empty:
        st.info("Grafik iÃ§in yeterli veri yok.")
        return
    cats = list(valid[x_col].astype(str).unique())
    data = [valid[valid[x_col].astype(str) == c][y_col].values for c in cats]
    fig, ax = plt.subplots()
    ax.boxplot(data, labels=cats, showmeans=True)
    ax.set_title(title)
    ax.set_xlabel(x_col)
    ax.set_ylabel(y_col)
    st.pyplot(fig)

def make_hist(df, col, bins=30, title="Histogram"):
    x = pd.to_numeric(df[col], errors="coerce").dropna()
    if x.empty:
        st.info("Histogram iÃ§in yeterli veri yok.")
        return
    fig, ax = plt.subplots()
    ax.hist(x, bins=bins)
    ax.set_title(title)
    ax.set_xlabel(col)
    ax.set_ylabel("Frekans")
    st.pyplot(fig)

def export_df(df, name="export.csv"):
    csv = df.to_csv(index=False).encode("utf-8-sig")
    st.download_button("â¬‡ï¸ CSV indir", data=csv, file_name=name, mime="text/csv")

# ============== Cache'li Dosya Okuma ============== #
@st.cache_data(show_spinner=False)
def read_one_excel_cached(file_bytes: bytes, engine_hint: str = "openpyxl") -> pd.DataFrame:
    bio = io.BytesIO(file_bytes)
    return pd.read_excel(bio, engine=engine_hint)

def read_many_excels(files):
    # Paralel okuma
    def _read(upl):
        try:
            data = upl.read()  # bytes
            df = read_one_excel_cached(data)
            return (upl.name, df, None)
        except Exception as e:
            return (upl.name, None, str(e))

    out = []
    with ThreadPoolExecutor(max_workers=min(8, len(files))) as ex:
        for name, df, err in ex.map(_read, files):
            out.append((name, df, err))
    return out

# ============== UI BaÅŸlangÄ±Ã§ ============== #
st.title("âš¡ Tetkik Analiz â€” Ã‡oklu Dosya (Optimize)")
st.caption("BÃ¼yÃ¼k veri ve Ã§oklu dosya iÃ§in hÄ±zlandÄ±rÄ±lmÄ±ÅŸ sÃ¼rÃ¼m.")

uploads = st.file_uploader("Excel dosyalarÄ± (.xlsx, .xls) â€” Ã‡oklu seÃ§im", type=["xlsx", "xls"], accept_multiple_files=True)

use_polars = st.checkbox("Polars hÄ±zlandÄ±rmayÄ± dene (kuruluysa)", value=HAS_POLARS and True,
                         help="Polars kurulu deÄŸilse otomatik devre dÄ±ÅŸÄ± kalÄ±r.")

if not uploads:
    st.info("Birden Ã§ok dosyayÄ± aynÄ± anda seÃ§in. Ã–rn: 12 dosya.")
    st.stop()

with st.spinner("Dosyalar okunuyor..."):
    results = read_many_excels(uploads)

frames = []
skipped = []
for name, tmp, err in results:
    if err:
        skipped.append((name, f"Okuma hatasÄ±: {err}"))
        continue
    miss = check_columns(tmp)
    if miss:
        skipped.append((name, f"Eksik sÃ¼tun: {miss}"))
        continue
    tmp["SOURCE_FILE"] = name
    frames.append(tmp)

if skipped:
    for nm, msg in skipped:
        st.warning(f"'{nm}' atlandÄ± â†’ {msg}")

if not frames:
    st.error("Uygun veri iÃ§eren dosya bulunamadÄ±.")
    st.stop()

# BirleÅŸtir
df = pd.concat(frames, ignore_index=True)
df = downcast_df(df)

# Polars'a Ã§evir (opsiyonel)
if use_polars and HAS_POLARS:
    try:
        pl_df = pl.from_pandas(df)
    except Exception:
        use_polars = False
        pl_df = None
else:
    pl_df = None

# ================= Filtreler ================= #
left, right = st.columns([3, 2])
with left:
    unique_tests = sorted([str(x) for x in df["TETKIK_ISMI"].dropna().unique()])
    default_pick = unique_tests[:5] if len(unique_tests) > 5 else unique_tests[:1]
    selected_tests = st.multiselect("Analiz edilecek tetkikler", options=unique_tests, default=default_pick)
with right:
    sexes = [str(x) for x in df["CINSIYET"].dropna().unique()]
    chosen_sex = st.multiselect("Cinsiyet filtresi", options=sexes, default=sexes)
    files = [str(x) for x in df["SOURCE_FILE"].dropna().unique()]
    chosen_files = st.multiselect("Dosya filtresi", options=files, default=files)

work = df.copy()
if chosen_sex:
    work = work[work["CINSIYET"].astype(str).isin(chosen_sex)]
if chosen_files:
    work = work[work["SOURCE_FILE"].astype(str).isin(chosen_files)]
if selected_tests:
    work = work[work["TETKIK_ISMI"].astype(str).isin(selected_tests)]

# ================= VARYANT Ã–ZETLERÄ° (Anormal Hb / HPLC â†’ Etiket + Ã–zet) ================= #
# === VARYANT Ã–ZETÄ° / ETÄ°KETLEME === (BAÅLA)
import re

# GÃ¼vence: numeric kopya olsun
work = add_numeric_copy(work)

# EriÅŸkin eÅŸik setleri
A2_KEYS = {"A2/", "HbA2", "HbA2 (%)", "Hb A2", "Hb A2 (%)"}
F_KEYS = {"F/", "HbF", "HbF (%)", "Hb F", "Hb F (%)"}

# TETKIK_ISMI -> varyant adÄ± (HPLC pikleri)
NUMVAR_FROM_TEST = {
    "C/": "HbC",
    "D/": "HbD",
    "E/": "HbE",
    "S/": "HbS",
}


def norm_anormal_hb_text(x: str | None):
    if not isinstance(x, str):
        return None
    s = x.upper().replace("Ä°", "I").strip()
    if re.search(r"S-?BETA|S ?Î²", s):
        return "Hb S-Î²-thal"
    if re.search(r"\bHBS\b|S TRAIT|S HET|HBS HET|HBS TAS|S-TASIY", s):
        return "HbS"
    if re.search(r"\bHBC\b", s):
        return "HbC"
    if re.search(r"\bHBD\b", s):
        return "HbD"
    if re.search(r"\bHBE\b", s):
        return "HbE"
    if re.search(r"\bA2\b|HBA2", s):
        return "HbA2â†‘"
    if re.search(r"\bF\b|HBF", s):
        return "HbFâ†‘"
    if re.search(r"\bNORMAL\b|NEG", s):
        return "Normal"
    return None


def pick_variant_tag(g: pd.DataFrame) -> str | None:
    g = add_numeric_copy(g.copy())
    g["TETKIK_ISMI"] = g["TETKIK_ISMI"].astype(str)
    tags = []

    # 1) Anormal Hb/ metinlerinden
    txt = g.loc[g["TETKIK_ISMI"] == "Anormal Hb/", "TEST_DEGERI"].dropna().astype(str)
    for v in txt:
        t = norm_anormal_hb_text(v)
        if t:
            tags.append(t)

    # 2) HbA2 ve HbF eriÅŸkin eÅŸikleri
    if g["TETKIK_ISMI"].isin(A2_KEYS).any():
        a2 = g.loc[g["TETKIK_ISMI"].isin(A2_KEYS), "__VAL_NUM__"].dropna()
        if not a2.empty and a2.max() >= 3.5:
            tags.append("HbA2â†‘")
    if g["TETKIK_ISMI"].isin(F_KEYS).any():
        f = g.loc[g["TETKIK_ISMI"].isin(F_KEYS), "__VAL_NUM__"].dropna()
        if not f.empty and f.max() > 2.0:
            tags.append("HbFâ†‘")

    # 3) HPLC pikleri (C/D/E/S) -> >0 varsa ilgili varyant
    for k, var_name in NUMVAR_FROM_TEST.items():
        m = g["TETKIK_ISMI"] == k
        if m.any():
            vv = g.loc[m, "__VAL_NUM__"].dropna()
            if not vv.empty and (vv > 0).any():
                tags.append(var_name)

    if not tags:
        return None
    priority = ["Hb S-Î²-thal", "HbS", "HbC", "HbD", "HbE", "HbA2â†‘", "HbFâ†‘", "Normal"]
    for p in priority:
        if p in tags:
            return p
    return tags[0]
# === VARYANT Ã–ZETÄ° / ETÄ°KETLEME === (BÄ°TÄ°R)


if "VARIANT_TAG" not in work.columns:
    # __VAL_NUM__ gÃ¼vence (tÃ¼m work Ã¼zerinde)
    work = add_numeric_copy(work)

    var_map = (work.groupby("PROTOKOL_NO", group_keys=False)
                  .apply(lambda g: pd.Series({"VARIANT_TAG": pick_variant_tag(g)}))
                  .reset_index())
    work = work.merge(var_map, on="PROTOKOL_NO", how="left")


# KullanÄ±cÄ± arayÃ¼zÃ¼
st.header("ğŸ“‹ Varyant Ã–zeti â€” eriÅŸkin eÅŸikleri ile")
st.caption(
    "Son halini Streamlit arayÃ¼zÃ¼nde anlÄ±k gÃ¶rebilmek iÃ§in `streamlit run app.py` komutunu Ã§alÄ±ÅŸtÄ±rabilirsiniz. "
    "Bu bÃ¶lÃ¼m, yÃ¼klediÄŸiniz verilere gÃ¶re her yeniden Ã§alÄ±ÅŸtÄ±rmada gÃ¼ncellenir."
)

# Sadece anlamlÄ± etiketleri (harfler) gÃ¶ster
order = ["Hb S-Î²-thal", "HbS", "HbC", "HbD", "HbE", "HbA2â†‘", "HbFâ†‘", "Normal"]
present = [t for t in order if t in set(work["VARIANT_TAG"].dropna())]

variant_choice = st.selectbox("Varyant seÃ§:", ["(TÃ¼mÃ¼)"] + present, index=0)

base_v = work.copy()
if variant_choice != "(TÃ¼mÃ¼)":
    base_v = base_v[base_v["VARIANT_TAG"] == variant_choice]

# 1) (TÃ¼mÃ¼) ise: frekans tablosu
if variant_choice == "(TÃ¼mÃ¼)":
    freq = (work["VARIANT_TAG"]
            .value_counts(dropna=True)
            .rename_axis("Varyant").to_frame("N").reset_index())
    total = int(freq["N"].sum()) if not freq.empty else 0
    if total > 0:
        freq["%"] = (freq["N"] / total * 100).round(2)
    st.subheader("Varyant FrekanslarÄ±")
    st.dataframe(freq, use_container_width=True)
    st.download_button("â¬‡ï¸ Varyant frekanslarÄ± (CSV)",
                       data=freq.to_csv(index=False).encode("utf-8-sig"),
                       file_name="varyant_frekans.csv", mime="text/csv")

# 2) SeÃ§ilen varyant iÃ§in Female/Male MeanÂ±SD tablosu ve olgu listesi
def _mean_sd(s: pd.Series):
    s = pd.to_numeric(s, errors="coerce").dropna()
    return "â€”" if s.empty else f"{s.mean():.2f} Â± {s.std(ddof=1):.2f}"

PARAMS = {
    "Hemogram/HGB":  ("Hb (g/dL)",   "F: 11â€“15; M: 12â€“17"),
    "Hemogram/HCT":  ("HCT (%)",     "F: 36â€“46; M: 40â€“53"),
    "Hemogram/RBC":  ("RBC (Ã—10â¶)",  "F: 3.9â€“5.6; M: 4.5â€“6.0"),
    "Hemogram/RDW":  ("RDW (%)",     "11â€“16"),
    "Hemogram/MCV":  ("MCV (fL)",    "80â€“100"),
    "Hemogram/MCH":  ("MCH (pg)",    "27â€“34"),
    "Hemogram/MCHC": ("MCHC (g/dL)", "32â€“36"),
    "HbA":           ("HbA (%)",     "94â€“98"),
    "HbA2 (%)":      ("HbAâ‚‚ (%)",    "2â€“3.5"),
    "A2/":           ("HbAâ‚‚ (%)",    "2â€“3.5"),
    "HbF (%)":       ("Hb F (%)",    "0â€“2"),
    "F/":            ("Hb F (%)",    "0â€“2"),
}

st.subheader("â™€/â™‚ Mean Â± SD (seÃ§ilen varyant)")
rows = []
for tetkik_key, (disp, ref) in PARAMS.items():
    subp = base_v[base_v["TETKIK_ISMI"] == tetkik_key].copy()
    if subp.empty: 
        continue
    subp = add_numeric_copy(subp)  # __VAL_NUM__ gÃ¼vence
    fem = _mean_sd(subp.loc[subp["CINSIYET"].astype(str).str.lower().str.startswith(("k","f")), "__VAL_NUM__"])
    male= _mean_sd(subp.loc[subp["CINSIYET"].astype(str).str.lower().str.startswith(("e","m")), "__VAL_NUM__"])
    rows.append({"Parameter": disp, "Female (Mean Â± SD)": fem, "Male (Mean Â± SD)": male, "Reference range": ref})

table_fm = pd.DataFrame(rows)
if table_fm.empty and variant_choice != "(TÃ¼mÃ¼)":
    st.info("Bu varyant iÃ§in parametrik veri bulunamadÄ±.")
else:
    st.dataframe(table_fm, use_container_width=True)
    st.download_button("â¬‡ï¸ Tablo #1 (CSV)",
                       data=table_fm.to_csv(index=False).encode("utf-8-sig"),
                       file_name="varyant_ozet_female_male.csv", mime="text/csv")

# Olgu listesi: seÃ§ili varyantta kimler var?
if variant_choice != "(TÃ¼mÃ¼)":
    cols_keep = ["PROTOKOL_NO", "TCKIMLIK_NO", "CINSIYET", "SOURCE_FILE"]
    cols_keep = [c for c in cols_keep if c in base_v.columns]
    case_tbl = base_v.drop_duplicates(subset=["PROTOKOL_NO"])[cols_keep + ["VARIANT_TAG"]]
    st.subheader("Olgu listesi (seÃ§ilen varyant)")
    st.dataframe(case_tbl, use_container_width=True)
    st.download_button("â¬‡ï¸ Olgu listesi (CSV)",
                       data=case_tbl.to_csv(index=False).encode("utf-8-sig"),
                       file_name=f"olgu_listesi_{variant_choice}.csv", mime="text/csv")


# ================= Ã–n-izleme & MÃ¼dahale: Metinden SayÄ±ya ================= #
import re
import numpy as np
import pandas as pd
import streamlit as st

# --- YardÄ±mcÄ±lar (esnek sayÄ± Ã§Ã¶zÃ¼cÃ¼) ---
def _dec_fix(x: str) -> str:
    s = x.replace("\xa0", " ").strip()
    # hem '.' hem ',' varsa: sondaki ayraÃ§ ondalÄ±k, diÄŸerleri binlik sayÄ±lÄ±r
    if "," in s and "." in s:
        last = max(s.rfind(","), s.rfind("."))
        dec = s[last]
        s = re.sub(r"[.,](?=\d{3}\b)", "", s)  # binlikleri at
        s = s.replace(dec, ".")
    elif "," in s:
        s = s.replace(".", "")         # olasÄ± binlik noktalarÄ±
        s = s.replace(",", ".")        # ondalÄ±k virgÃ¼l â†’ nokta
    else:
        s = re.sub(r"\.(?=\d{3}\b)", "", s)  # binlik noktayÄ± at
    return s

def smart_number(text: str):
    """Ã–neri Ã¼retir (float veya None). Birimleri, %, < >, aralÄ±klarÄ± yakalar."""
    if text is None: 
        return None
    s = str(text).strip().lower()
    if s in {"", "nan", "na", "n/a", "yok", "boÅŸ", "empty", "nd"}:
        return None
    if s in {"pozitif", "+", "positive", "pos"}: return 1.0
    if s in {"negatif", "-", "negative", "neg"}: return 0.0

    # yÃ¼zde (15% â†’ 15)
    s = s.replace("%", " ")

    # eÅŸitsizlikler (<, â‰¤, >, â‰¥) â†’ sÄ±nÄ±r deÄŸer (isteÄŸe gÃ¶re geliÅŸtirebiliriz)
    m_ineq = re.match(r"^\s*([<>]=?)\s*([0-9.,]+)", s)
    if m_ineq:
        op, num = m_ineq.groups()
        try: v = float(_dec_fix(num))
        except: v = None
        return v

    # aralÄ±klar (12â€“14, 12-14) â†’ ortalama
    m_rng = re.match(r"^\s*([+-]?\d[\d.,]*)\s*[-â€“â€”]\s*([+-]?\d[\d.,]*)", s)
    if m_rng:
        a, b = m_rng.groups()
        try:
            a = float(_dec_fix(a)); b = float(_dec_fix(b))
            return (a + b) / 2.0
        except:
            return None

    # metin iÃ§indeki ilk sayÄ±yÄ± Ã§ek (12,3 g/dL vb.)
    m_any = re.search(r"[+-]?\d[\d.,]*", s)
    if m_any:
        try: return float(_dec_fix(m_any.group(0)))
        except: return None

    return None

# --- Problem yakalama: Ã–neri + iÅŸaretleme ---
orig = work["TEST_DEGERI"].astype(str)
suggested = orig.map(smart_number)

# â€œproblemliâ€ kriteri: numeric'e Ã§evrilemiyor ya da metinde iÅŸaret/harf/aralÄ±k var
is_categorical_row = work["TETKIK_ISMI"].astype(str).isin(CATEGORICAL_TESTS)
mask_problem = (
    (~is_categorical_row) & (
        suggested.isna() |
        orig.str.contains(r"[A-Za-z%<>]|[-â€“â€”].*[-â€“â€”]", regex=True)
    )
)

# Ä°nceleme tablosu: orijinal + Ã¶neri + dÃ¼zenlenebilir hedef
preview = work.loc[mask_problem, [
    "TETKIK_ISMI", "CINSIYET", "PROTOKOL_NO", "TCKIMLIK_NO", "TEST_DEGERI"
]].copy()

preview = preview.reset_index().rename(columns={"index": "__ROW_ID__"})
preview["SUGGESTED"] = suggested.loc[preview["__ROW_ID__"]].values

st.header("ğŸ§¹ Problemli DeÄŸerler â€” Ã–n-izleme & MÃ¼dahale")
st.caption("AÅŸaÄŸÄ±da metin iÃ§erikli/sorunlu tÃ¼m deÄŸerler listelenir. 'CLEAN_VALUE' sÃ¼tununu elle dÃ¼zeltebilirsin.")

# DÃ¼zenlenebilir sÃ¼tun: CLEAN_VALUE (baÅŸlangÄ±Ã§ta Ã¶neri)
preview["CLEAN_VALUE"] = preview["SUGGESTED"]

edited = st.data_editor(
    preview,
    use_container_width=True,
    num_rows="fixed",
    column_config={
        "__ROW_ID__": st.column_config.NumberColumn(label="RowID", help="Orijinal satÄ±r indeksi", disabled=True),
        "TEST_DEGERI": st.column_config.TextColumn(label="ORIGINAL", help="Ham deÄŸer", disabled=True),
        "SUGGESTED": st.column_config.NumberColumn(label="Ã–NERÄ° (otomatik)", help="AlgoritmanÄ±n Ã¶nerdiÄŸi", disabled=True),
        "CLEAN_VALUE": st.column_config.NumberColumn(label="CLEAN_VALUE (elle dÃ¼zenle)", help="BurayÄ± istediÄŸin gibi deÄŸiÅŸtir"),
    },
    hide_index=True
)

col_apply, col_opts = st.columns([1,1])
with col_apply:
    apply_now = st.button("âœ… DÃ¼zenlemeleri uygula (TEST_DEGERI_CLEAN)")

with col_opts:
    overwrite_main = st.checkbox("TEST_DEGERI sÃ¼tununu CLEAN_VALUE ile deÄŸiÅŸtir", value=False)

if apply_now:
    # Son kullanÄ±cÄ±nÄ±n girdiklerini orijinal work'e geri yaz
    updates = edited[["__ROW_ID__", "CLEAN_VALUE"]].dropna(subset=["__ROW_ID__"])
    work.loc[updates["__ROW_ID__"].values, "TEST_DEGERI_CLEAN"] = updates["CLEAN_VALUE"].values

    if overwrite_main:
        work.loc[updates["__ROW_ID__"].values, "TEST_DEGERI"] = updates["CLEAN_VALUE"].values

    st.success(
        f"GÃ¼ncellendi: {updates['__ROW_ID__'].nunique():,} satÄ±r iÃ§in CLEAN_VALUE uygulandÄ±. "
        f"{'TEST_DEGERI de gÃ¼ncellendi.' if overwrite_main else 'TEST_DEGERI_CLEAN sÃ¼tunu oluÅŸturuldu/gÃ¼ncellendi.'}"
    )
    st.download_button(
        "â¬‡ï¸ Temiz/duzeltilmiÅŸ veriyi indir (CSV)",
        data=work.to_csv(index=False).encode("utf-8-sig"),
        file_name="temizlenmis_veri.csv",
        mime="text/csv"
    )



# ================= Genel Bilgiler ================= #
st.subheader("ğŸ” Genel Bilgiler (BirleÅŸtirilmiÅŸ)")
c1, c2, c3, c4, c5 = st.columns(5)
c1.metric("Toplam SatÄ±r", f"{len(df):,}")
c2.metric("Benzersiz TCKIMLIK_NO", f"{df['TCKIMLIK_NO'].nunique():,}")
c3.metric("Benzersiz Tetkik", f"{df['TETKIK_ISMI'].nunique():,}")
c4.metric("Benzersiz Cinsiyet", f"{df['CINSIYET'].nunique():,}")
c5.metric("Dosya SayÄ±sÄ±", f"{df['SOURCE_FILE'].nunique():,}")

with st.expander("Ham Veri Ã–n Ä°zleme (limitli)"):
    st.dataframe(work.head(DISPLAY_LIMIT), use_container_width=True)
    st.caption(f"YalnÄ±zca ilk {DISPLAY_LIMIT} satÄ±r gÃ¶rÃ¼ntÃ¼lenir.")

# ================= HÄ±zlÄ± Ã–zetler ================= #
st.header("âš™ï¸ HÄ±zlÄ± Ã–zet ve KÄ±rÄ±lÄ±mlar")
colA, colB = st.columns(2)
with colA:
    st.write("**Cinsiyete GÃ¶re TanÄ±mlayÄ±cÄ±lar (SeÃ§imdeki veri)**")
    if use_polars and pl_df is not None:
        pl_sub = pl.from_pandas(work[["CINSIYET", "TEST_DEGERI"]].copy())
        grp = (pl_sub
               .groupby("CINSIYET")
               .agg([pl.len().alias("count"),
                     pl.col("TEST_DEGERI").mean().alias("mean"),
                     pl.col("TEST_DEGERI").std().alias("std"),
                     pl.col("TEST_DEGERI").min().alias("min"),
                     pl.col("TEST_DEGERI").median().alias("median"),
                     pl.col("TEST_DEGERI").quantile(0.25, "nearest").alias("q1"),
                     pl.col("TEST_DEGERI").quantile(0.75, "nearest").alias("q3"),
                     pl.col("TEST_DEGERI").max().alias("max")])
               .to_pandas())
        st.dataframe(grp, use_container_width=True)
    else:
        grp = (work.groupby("CINSIYET", dropna=False)["TEST_DEGERI"]
               .agg(["count", "mean", "std", "min", "median", "max"]).reset_index())
        st.dataframe(grp, use_container_width=True)

with colB:
    st.write("**Dosyaya GÃ¶re SatÄ±r & Hasta & Tetkik SayÄ±sÄ±**")
    per_file = work.groupby("SOURCE_FILE").agg(
        N=("PROTOKOL_NO", "size"),
        Hasta_Sayisi=("TCKIMLIK_NO", "nunique"),
        Tetkik_Sayisi=("TETKIK_ISMI", "nunique")
    ).reset_index()
    st.dataframe(per_file, use_container_width=True)
    export_df(per_file, "dosya_bazinda_ozet_filtreli.csv")

# ================= Tetkik BazlÄ± Analiz ================= #
st.header("ğŸ“Š Tetkik BazlÄ± Analiz (SeÃ§im)")

results_rows = []

for test_name in selected_tests:
    sub = work[work["TETKIK_ISMI"].astype(str) == test_name].copy()
    if sub.empty:
        continue

    # --- KATEGORÄ°K TESTLER (Kan Grubu, Anormal Hb) ---
    if test_name in {"Kan Grubu/", "Anormal Hb/"}:
        st.info("Bu tetkik kategorik olarak deÄŸerlendirildi (frekans analizi).")

        import re
        def normalize_blood_group(x):
            if not isinstance(x, str): return None
            s = x.upper().replace("Ä°","I").strip()
            abo = None
            if re.search(r"\bAB\b", s): abo = "AB"
            elif re.search(r"\bA\b", s): abo = "A"
            elif re.search(r"\bB\b", s): abo = "B"
            elif re.search(r"\b0\b|\bO\b", s): abo = "O"
            rh = "Rh(+)" if re.search(r"(\+|POS|POZ|RH\+)", s) else ("Rh(-)" if re.search(r"(\-|NEG)", s) else "")
            return (abo + (" " + rh if rh else "")).strip() if abo else s

        def normalize_anormal_hb_text(x):
            if not isinstance(x, str): return None
            s = x.upper().replace("Ä°","I").strip()
            if re.search(r"S-?BETA|S ?Î²", s): return "Hb S-Î²-thal"
            if re.search(r"\bHBS\b|S TRAIT|S HET|HBS HET|HBS TAS|S-TASIY", s): return "HbS"
            if re.search(r"\bHBC\b", s): return "HbC"
            if re.search(r"\bHBD\b", s): return "HbD"
            if re.search(r"\bHBE\b", s): return "HbE"
            if re.search(r"\bA2\b|HBA2", s): return "HbA2â†‘"
            if re.search(r"\bF\b|HBF", s): return "HbFâ†‘"
            if re.search(r"\bNORMAL\b|NEG", s): return "Normal"
            return s or None

        if test_name == "Kan Grubu/":
            cat_series = sub["TEST_DEGERI"].map(normalize_blood_group)
        else:
            cat_series = sub["TEST_DEGERI"].map(normalize_anormal_hb_text)

        sub_cat = sub.assign(__CAT__=cat_series)

        # ---- Frekans tablosu ----
        freq_all = (sub_cat["__CAT__"].value_counts(dropna=False)
                    .rename_axis("Kategori").to_frame("N").reset_index())
        total = int(freq_all["N"].sum()) if not freq_all.empty else 0
        if total > 0:
            freq_all["%"] = (freq_all["N"]/total*100).round(2)

        freq_by_sex = (sub_cat.pivot_table(index="__CAT__", columns="CINSIYET",
                                           values="PROTOKOL_NO", aggfunc="count", fill_value=0)
                       .astype(int).reset_index().rename(columns={"__CAT__":"Kategori"}))

        from scipy.stats import chi2_contingency
        chi2_msg = "Ki-kare uygulanamadÄ±."
        try:
            cont = freq_by_sex.drop(columns=["Kategori"]).values
            if cont.sum() > 0 and cont.shape[1] > 1:
                chi2, p, dof, _ = chi2_contingency(cont)
                chi2_msg = f"Chi-square: Ï‡Â²={chi2:.2f}, df={dof}, p={p:.4g}"
        except Exception as e:
            chi2_msg = f"Hata: {e}"

        tabs = st.tabs(["Frekans", "Cinsiyet DaÄŸÄ±lÄ±mÄ±", "Ä°statistik", "Olgu Listesi"])
        with tabs[0]:
            st.dataframe(freq_all, use_container_width=True)
        with tabs[1]:
            st.dataframe(freq_by_sex, use_container_width=True)
        with tabs[2]:
            st.info(chi2_msg)
        with tabs[3]:
            keep = ["PROTOKOL_NO","TCKIMLIK_NO","CINSIYET","SOURCE_FILE"]
            keep = [c for c in keep if c in sub_cat.columns]
            case_tbl = sub_cat[keep + ["TEST_DEGERI","__CAT__"]].rename(columns={"__CAT__":"Kategori"})
            st.dataframe(case_tbl, use_container_width=True)
            st.download_button("â¬‡ï¸ Olgu listesi (CSV)",
                data=case_tbl.to_csv(index=False).encode("utf-8-sig"),
                file_name=f"{test_name}_olgu_listesi.csv", mime="text/csv")

        results_rows.append({
            "TETKIK_ISMI": test_name,
            "N": int(freq_all["N"].sum()),
            "Mean": None, "Median": None, "Std": None,
            "Min": None, "Q1": None, "Q3": None, "Max": None,
            "Normalite": "â€”", "Test": chi2_msg
        })


    # sayÄ±sal kopya hazÄ±rla
    sub = add_numeric_copy(sub)

    st.subheader(f"ğŸ§· {test_name}")

    # --- KATEGORÄ°K MÄ°? ---
    is_categorical = (test_name in CATEGORICAL_TESTS)
    if not is_categorical:
        # veri temelli kontrol (sayÄ±sal oranÄ± Ã§ok dÃ¼ÅŸÃ¼kse kategorik say)
        num_ratio = sub["__VAL_NUM__"].notna().mean()
        if num_ratio < 0.3:
            is_categorical = True

    if is_categorical:
        st.info("Bu tetkik kategorik olarak deÄŸerlendirildi (frekans analizi).")

        freq_all = (sub["TEST_DEGERI"].astype(str).str.strip()
                    .value_counts(dropna=False).rename_axis("Kategori")
                    .to_frame("N").reset_index())
        freq_all["%"] = (freq_all["N"] / freq_all["N"].sum() * 100).round(2)

        freq_by_sex = (sub.pivot_table(index="TEST_DEGERI", columns="CINSIYET",
                                       values="PROTOKOL_NO", aggfunc="count", fill_value=0)
                       .astype(int).reset_index().rename(columns={"TEST_DEGERI":"Kategori"}))

        chi2_msg = "Ki-kare uygulanamadÄ±."
        try:
            from scipy.stats import chi2_contingency
            cont = freq_by_sex.drop(columns=["Kategori"]).values
            if cont.sum() > 0 and cont.shape[1] > 1:
                chi2, p, dof, _ = chi2_contingency(cont)
                chi2_msg = f"Chi-square: Ï‡Â²={chi2:.2f}, df={dof}, p={p:.4g}"
        except Exception as e:
            chi2_msg = f"Hata: {e}"

        tabs = st.tabs(["Frekans", "Cinsiyet DaÄŸÄ±lÄ±mÄ±", "Ä°statistik"])
        with tabs[0]: st.dataframe(freq_all, use_container_width=True)
        with tabs[1]: st.dataframe(freq_by_sex, use_container_width=True)
        with tabs[2]: st.info(chi2_msg)

        results_rows.append({
            "TETKIK_ISMI": test_name, "N": int(freq_all["N"].sum()),
            "Mean": None, "Median": None, "Std": None, "Min": None, "Q1": None, "Q3": None, "Max": None,
            "Normalite": "â€”", "Test": chi2_msg
        })
        continue  # sayÄ±sal kola girme

    # --- SAYISAL ANALÄ°Z (tek Ã§erÃ§eve: sub_work) ---
    use_threshold = st.checkbox(
        f"â€˜{test_name}â€™ iÃ§in eriÅŸkin eÅŸiÄŸini uygula",
        value=(test_name in THRESHOLDS),
        key=f"th_{test_name}"
    )
    use_gt_zero  = st.checkbox(
        f"â€˜{test_name}â€™ iÃ§in sadece > 0 deÄŸerleri dahil et",
        value=(test_name in GT_ZERO_DEFAULT),
        key=f"gt0_{test_name}"
    )

    sub_work = sub[sub["__VAL_NUM__"].notna()].copy()
    if use_threshold and test_name in THRESHOLDS:
        sub_work = sub_work[apply_threshold(sub_work["__VAL_NUM__"], THRESHOLDS[test_name])]
        st.caption(f"EÅŸik: {THRESHOLDS[test_name][0]} {THRESHOLDS[test_name][1]}")
    elif use_gt_zero:
        sub_work = sub_work[sub_work["__VAL_NUM__"] > 0]
        st.caption("Filtre: > 0")

    if sub_work.empty:
        st.warning("Filtre sonrasÄ± satÄ±r bulunamadÄ±.")
        continue

    # TanÄ±mlayÄ±cÄ±lar
    stats_overall = descr_stats_fast(sub_work["__VAL_NUM__"])
    normal_flag   = normality_flag(sub_work["__VAL_NUM__"])

    # Cinsiyet / Dosya kÄ±rÄ±lÄ±mlarÄ±
    by_sex = (sub_work.groupby("CINSIYET", dropna=False)["__VAL_NUM__"]
              .agg(count="count", mean="mean", std="std", min="min", median="median", max="max")).reset_index()

    by_file = (sub_work.groupby("SOURCE_FILE", dropna=False)["__VAL_NUM__"]
               .agg(count="count", mean="mean", std="std", min="min", median="median", max="max")).reset_index()

    # Nonparametrik test
    _msg_df = sub_work.rename(columns={"__VAL_NUM__": "VAL"})
    msg, test_info = nonparametric_test_by_group(_msg_df, "VAL", "CINSIYET")

    results_rows.append({
        "TETKIK_ISMI": test_name,
        "N": stats_overall["count"],
        "Mean": stats_overall["mean"],
        "Median": stats_overall["median"],
        "Std": stats_overall["std"],
        "Min": stats_overall["min"],
        "Q1": stats_overall["q1"],
        "Q3": stats_overall["q3"],
        "Max": stats_overall["max"],
        "Normalite": normal_flag,
        "Test": msg
    })

    # Sekmeler
    tabs = st.tabs(["TanÄ±mlayÄ±cÄ±", "Cinsiyet", "Dosya", "Ä°statistiksel Test", "Histogram", "Boxplot"])
    with tabs[0]: st.table(pd.DataFrame([stats_overall]))
    with tabs[1]: st.dataframe(by_sex, use_container_width=True)
    with tabs[2]: st.dataframe(by_file, use_container_width=True)
    with tabs[3]: st.info(msg)
    with tabs[4]:
        if st.checkbox(f"Histogram gÃ¶ster ({test_name})", value=False):
            make_hist(_msg_df, "VAL", bins=30, title=f"{test_name} - Histogram")
    with tabs[5]:
        if st.checkbox(f"Boxplot gÃ¶ster ({test_name})", value=False):
            make_boxplot(sub_work, "CINSIYET", "__VAL_NUM__", title=f"{test_name} - Cinsiyete GÃ¶re Boxplot")

    # Pozitif (filtre sonrasÄ±) liste
    pos_cols = ["PROTOKOL_NO", "TCKIMLIK_NO", "CINSIYET", "SOURCE_FILE"]
    pos_cols = [c for c in pos_cols if c in sub_work.columns]
    pos_tbl = sub_work[pos_cols + ["__VAL_NUM__"]].sort_values("__VAL_NUM__", ascending=False)
    st.write("**Filtre sonrasÄ± kayÄ±tlar**")
    st.dataframe(pos_tbl, use_container_width=True)
    st.download_button(
        "â¬‡ï¸ TCKIMLIK_NO listesi (CSV)",
        data=pos_tbl.to_csv(index=False).encode("utf-8-sig"),
        file_name=f"{test_name}_filtre_sonrasi.csv",
        mime="text/csv"
    )


# Toplu Ã¶zet
if results_rows:
    st.header("ğŸ§¾ Toplu Ã–zet Tablosu (SeÃ§ili Tetkikler)")
    res_df = pd.DataFrame(results_rows)
    st.dataframe(res_df, use_container_width=True)
    export_df(res_df, name="tetkik_ozet.csv")

# ================= Otomatik Rapor (TÃ¼m Tetkikler) ================= #
st.header("ğŸ“‘ Otomatik Rapor (TÃ¼m Tetkikler)")
if st.button("Raporu Ã¼ret (tam veri)"):
    rows = []
    for t in sorted(df["TETKIK_ISMI"].dropna().astype(str).unique()):
        sub = df[df["TETKIK_ISMI"].astype(str) == t].copy()
        sub["TEST_DEGERI"] = pd.to_numeric(sub["TEST_DEGERI"], errors="coerce")
        sub = sub.dropna(subset=["TEST_DEGERI"])
        if sub.empty:
            continue
        stats_overall = descr_stats_fast(sub["TEST_DEGERI"])
        msg, _ = nonparametric_test_by_group(sub, "TEST_DEGERI", "CINSIYET")
        rows.append({
            "TETKIK_ISMI": t,
            "N": stats_overall["count"],
            "Mean": stats_overall["mean"],
            "Median": stats_overall["median"],
            "Std": stats_overall["std"],
            "Min": stats_overall["min"],
            "Q1": stats_overall["q1"],
            "Q3": stats_overall["q3"],
            "Max": stats_overall["max"],
            "Normalite": normality_flag(sub["TEST_DEGERI"]),
            "Test": msg
        })
    if rows:
        rpt = pd.DataFrame(rows)
        st.success("Rapor hazÄ±rlandÄ±.")
        st.dataframe(rpt, use_container_width=True)
        export_df(rpt, name="tum_tetkikler_rapor.csv")
    else:
        st.warning("Rapor iÃ§in uygun veri bulunamadÄ±.")

st.caption("Performans ipuÃ§larÄ±: Ã‡ok dosya yÃ¼klerken Polars seÃ§eneÄŸini aÃ§Ä±n, grafikleri ihtiyaÃ§ duydukÃ§a gÃ¶sterin, bÃ¼yÃ¼k tablolarÄ± CSV olarak indirip lokal inceleyin.")
'''

with open('app.py', 'w', encoding='utf-8') as f:
    f.write(app_code)

'/mnt/data/app_optimized.py'
# ================= Klinik Tablo (Î²-talasemi tarzÄ±) ================= #
st.header("ğŸ“‹ Klinik Tablo â€” Hematolojik Bulgular (Otomatik)")

src_choice = st.radio(
    "Veri kaynaÄŸÄ±",
    ["SeÃ§imdeki veri (work)", "TÃ¼m veri (df)"],
    index=0,
    horizontal=True
)
base = work.copy() if src_choice.startswith("SeÃ§imdeki") else df.copy()

# Hedef parametreler ve referans aralÄ±klarÄ± (gerekirse dÃ¼zenleyebilirsin)
params = [
    ("Age (years)", None),   # YaÅŸ yoksa otomatik boÅŸ kalÄ±r
    ("Hb (g/dL)", "Hb"),     # (TETKIK_ISMI'ndeki ad)
    ("HCT (%)", "HCT"),
    ("RBC (Ã—10â¶)", "RBC"),
    ("RDW (%)", "RDW"),
    ("MCV (fL)", "MCV"),
    ("MCH (pg)", "MCH"),
    ("MCHC (g/dL)", "MCHC"),
    ("HbA (%)", "HbA"),
    ("HbAâ‚‚ (%)", "HbA2"),
    ("Hb F (%)", "HbF"),
]

ref_ranges = {
    "Hb (g/dL)": "F: 11â€“15; M: 12â€“17",
    "HCT (%)":   "F: 36â€“46; M: 40â€“53",
    "RBC (Ã—10â¶)": "F: 3.9â€“5.6; M: 4.5â€“6.0",
    "RDW (%)":   "11â€“16",
    "MCV (fL)":  "80â€“100",
    "MCH (pg)":  "27â€“34",
    "MCHC (g/dL)": "32â€“36",
    "HbA (%)":   "94â€“98",
    "HbAâ‚‚ (%)":  "2â€“3.5",
    "Hb F (%)":  "0â€“2",
    "Age (years)": "â€”",
}

# Cinsiyet normalizasyonu
sex_map = {
    "e": "Male", "erkek": "Male", "m": "Male", "male": "Male",
    "k": "Female","kadÄ±n":"Female","f":"Female","female":"Female"
}
base["__SEX__"] = (
    base["CINSIYET"].astype(str).str.strip().str.lower().map(sex_map)
)
# TEST_DEGERI sayÄ±sal gÃ¼vence
base["__VAL__"] = pd.to_numeric(
    base["TEST_DEGERI"].astype(str).str.replace(",", ".", regex=False),
    errors="coerce"
)

def fmt_mean_sd(s: pd.Series, nd=2):
    s = pd.to_numeric(s, errors="coerce").dropna()
    if len(s) == 0:
        return "â€”"
    return f"{s.mean():.{nd}f} Â± {s.std(ddof=1):.{nd}f}"

rows = []
for label, tetkik_ismi in params:
    # Age yoksa "â€”" bÄ±rak (datasetinde AGE sÃ¼tunu varsa 'AGE'â†’numeric yapÄ±p buraya entegre edebilirsin)
    if tetkik_ismi is None:
        female = "â€”"
        male = "â€”"
    else:
        sub = base[base["TETKIK_ISMI"].astype(str) == tetkik_ismi].copy()
        female = fmt_mean_sd(sub.loc[sub["__SEX__"]=="Female", "__VAL__"])
        male   = fmt_mean_sd(sub.loc[sub["__SEX__"]=="Male", "__VAL__"])

    rows.append({
        "Parameter": label,
        "Female (Mean Â± SD)": female,
        "Male (Mean Â± SD)": male,
        "Reference range": ref_ranges.get(label, "â€”")
    })

table_df = pd.DataFrame(rows)

# GÃ¶rÃ¼ntÃ¼le + indir
st.dataframe(table_df, use_container_width=True)
csv_bytes = table_df.to_csv(index=False).encode("utf-8-sig")
st.download_button("â¬‡ï¸ Tabloyu CSV indir", data=csv_bytes, file_name="klinik_tablo.csv", mime="text/csv")

st.caption(
    "Not: Cinsiyet eÅŸleÅŸtirmesi E/K/Erkek/KadÄ±n/Male/Female yazÄ±mlarÄ±nÄ± otomatik algÄ±lar. "
    "YaÅŸ (Age) veriniz yoksa satÄ±r 'â€”' kalÄ±r. Ä°stersen AGE/YAÅ sÃ¼tununu eklersen hesaplarÄ±m."
)
