# Create an optimized version of the Streamlit app with performance improvements for many files.
# Key upgrades:
# - Cached, parallel file reading
# - Optional Polars backend (if installed)
# - Downcasting dtypes + categorical conversion
# - On-demand charts (to avoid rendering overhead)
# - Vectorized per-group stats via pandas agg
# - Heavier ops hidden behind expanders
# - Safer large-data display (sample/limit)

app_code = r'''
# -*- coding: utf-8 -*-
"""
ğŸ§ª Tetkik Analiz ArayÃ¼zÃ¼ â€” Ã‡oklu Dosya (Optimize)
- Ã‡oklu dosya iÃ§in hÄ±zlÄ± okuma (paralel + cache)
- Bellek optimizasyonu (downcast, categorical)
- Ä°steÄŸe baÄŸlÄ± Polars hÄ±zlandÄ±rma (kuruluysa)
- BÃ¼yÃ¼k tablolarÄ± temkinli gÃ¶sterim (Ã¶rnekleme/limit)
- Grafikler isteÄŸe baÄŸlÄ± oluÅŸturulur (butonlar/checkbox), matplotlib (renk set edilmez)
Kurulum:
    pip install streamlit pandas numpy scipy openpyxl matplotlib
(opsiyonel hÄ±zlandÄ±rma)
    pip install polars pyarrow
Ã‡alÄ±ÅŸtÄ±rma:
    streamlit run app_optimized.py
"""

import io
import math
import numpy as np
import pandas as pd
import streamlit as st
from scipy import stats
import matplotlib.pyplot as plt
from concurrent.futures import ThreadPoolExecutor

# ============== Ayarlar ============== #
st.set_page_config(page_title="Tetkik Analiz â€” Optimize", layout="wide")
REQ_COLS = ["PROTOKOL_NO", "TCKIMLIK_NO", "TETKIK_ISMI", "TEST_DEGERI", "CINSIYET"]
# Standart kategorik tetkikler (metin sonucu Ã¼reten)
CATEGORICAL_TESTS = {
    "Kan Grubu/",
    "Anormal Hb/",
    "Talasemi(HPLC) (A0)/",
}
# >0 ise "pozitif" sayÄ±lacak varyant yÃ¼zdeleri (ihtiyacÄ±na gÃ¶re geniÅŸlet)
VARIANT_NUMERIC_TESTS = {
    "HbS (%)", "HbC (%)", "HbD (%)", "HbE (%)",
    "HbF (%)", "HbA2 (%)",   # eÅŸik kullanacaksan ayrÄ±ca ekleriz
    "Anormal Hb/"            # sayÄ± geliyorsa >0 filtre uygular
}
DISPLAY_LIMIT = 200  # BÃ¼yÃ¼k veri iÃ§in Ã¶nizleme limiti

# Polars mevcut mu?
try:
    import polars as pl
    HAS_POLARS = True
except Exception:
    HAS_POLARS = False

# ============== YardÄ±mcÄ±lar ============== #
def coerce_numeric(series: pd.Series) -> pd.Series:
    s = series.astype(str).str.replace(",", ".", regex=False).str.replace(" ", "", regex=False)
    return pd.to_numeric(s, errors="coerce")

def check_columns(df: pd.DataFrame):
    return [c for c in REQ_COLS if c not in df.columns]

def downcast_df(df: pd.DataFrame) -> pd.DataFrame:
    # PROTOKOL_NO, TCKIMLIK_NO sayÄ±ya dÃ¶nmesin (ID olabilir), diÄŸer uygun alanlarÄ± kÃ¼Ã§Ã¼lt
    # TEST_DEGERI numerik
    if "TEST_DEGERI" in df.columns:
        df["TEST_DEGERI"] = coerce_numeric(df["TEST_DEGERI"])
        df["TEST_DEGERI"] = pd.to_numeric(df["TEST_DEGERI"], errors="coerce", downcast="float")
    # Kategorik alanlar
    for col in ["TETKIK_ISMI", "CINSIYET", "SOURCE_FILE"]:
        if col in df.columns:
            df[col] = df[col].astype("category")
    return df

def descr_stats_fast(x: pd.Series) -> dict:
    x = pd.to_numeric(x, errors="coerce")
    x = x[~x.isna()]
    if x.empty:
        return {"count": 0, "mean": np.nan, "std": np.nan, "min": np.nan,
                "q1": np.nan, "median": np.nan, "q3": np.nan, "max": np.nan,
                "cv%": np.nan, "iqr": np.nan}
    q = np.percentile(x, [25, 50, 75])
    mean = float(x.mean())
    std = float(x.std(ddof=1)) if len(x) > 1 else 0.0
    cv = (std / mean) * 100 if mean != 0 else np.nan
    return {
        "count": int(x.size),
        "mean": mean,
        "std": std,
        "min": float(x.min()),
        "q1": float(q[0]),
        "median": float(q[1]),
        "q3": float(q[2]),
        "max": float(x.max()),
        "cv%": float(cv),
        "iqr": float(q[2] - q[0]),
    }

def normality_flag(x: pd.Series, alpha=0.05) -> str:
    x = pd.to_numeric(x, errors="coerce").dropna()
    if len(x) < 3:
        return "yetersiz"
    try:
        if len(x) <= 5000:
            stat, p = stats.shapiro(x)
            return "normal" if p >= alpha else "non-normal"
        else:
            res = stats.anderson(x, dist="norm")
            crit = res.critical_values[2]  # 5%
            return "normal" if res.statistic < crit else "non-normal"
    except Exception:
        return "bilinmiyor"

def nonparametric_test_by_group(df, val_col, grp_col):
    # Gruplar
    groups = [g.dropna() for _, g in df.groupby(grp_col)[val_col]]
    groups = [pd.to_numeric(g, errors="coerce").dropna() for g in groups]
    groups = [g for g in groups if len(g) > 0]
    unique_groups = df[grp_col].dropna().unique()
    unique_groups = [g for g in unique_groups if df[df[grp_col] == g][val_col].notna().sum() > 0]

    if len(unique_groups) < 2:
        return "KarÅŸÄ±laÅŸtÄ±rma iÃ§in en az 2 grup gerekli.", None

    if len(unique_groups) == 2:
        gnames = list(unique_groups)
        x = pd.to_numeric(df[df[grp_col] == gnames[0]][val_col], errors="coerce").dropna()
        y = pd.to_numeric(df[df[grp_col] == gnames[1]][val_col], errors="coerce").dropna()
        if len(x) >= 1 and len(y) >= 1:
            stat, p = stats.mannwhitneyu(x, y, alternative="two-sided")
            return f"Mannâ€“Whitney U: U={stat:.2f}, p={p:.4g} ({gnames[0]} vs {gnames[1]})", ("MWU", stat, p, gnames[0], gnames[1])
        else:
            return "Gruplarda yeterli gÃ¶zlem yok.", None
    else:
        stat, p = stats.kruskal(*groups)
        return f"Kruskalâ€“Wallis: H={stat:.2f}, p={p:.4g} (grup sayÄ±sÄ±: {len(unique_groups)})", ("KW", stat, p, unique_groups)

def make_boxplot(df, x_col, y_col, title="Kutu GrafiÄŸi"):
    valid = df[[x_col, y_col]].copy()
    valid[y_col] = pd.to_numeric(valid[y_col], errors="coerce")
    valid = valid.dropna()
    if valid.empty:
        st.info("Grafik iÃ§in yeterli veri yok.")
        return
    cats = list(valid[x_col].astype(str).unique())
    data = [valid[valid[x_col].astype(str) == c][y_col].values for c in cats]
    fig, ax = plt.subplots()
    ax.boxplot(data, labels=cats, showmeans=True)
    ax.set_title(title)
    ax.set_xlabel(x_col)
    ax.set_ylabel(y_col)
    st.pyplot(fig)

def make_hist(df, col, bins=30, title="Histogram"):
    x = pd.to_numeric(df[col], errors="coerce").dropna()
    if x.empty:
        st.info("Histogram iÃ§in yeterli veri yok.")
        return
    fig, ax = plt.subplots()
    ax.hist(x, bins=bins)
    ax.set_title(title)
    ax.set_xlabel(col)
    ax.set_ylabel("Frekans")
    st.pyplot(fig)

def export_df(df, name="export.csv"):
    csv = df.to_csv(index=False).encode("utf-8-sig")
    st.download_button("â¬‡ï¸ CSV indir", data=csv, file_name=name, mime="text/csv")

# ============== Cache'li Dosya Okuma ============== #
@st.cache_data(show_spinner=False)
def read_one_excel_cached(file_bytes: bytes, engine_hint: str = "openpyxl") -> pd.DataFrame:
    bio = io.BytesIO(file_bytes)
    return pd.read_excel(bio, engine=engine_hint)

def read_many_excels(files):
    # Paralel okuma
    def _read(upl):
        try:
            data = upl.read()  # bytes
            df = read_one_excel_cached(data)
            return (upl.name, df, None)
        except Exception as e:
            return (upl.name, None, str(e))

    out = []
    with ThreadPoolExecutor(max_workers=min(8, len(files))) as ex:
        for name, df, err in ex.map(_read, files):
            out.append((name, df, err))
    return out

# ============== UI BaÅŸlangÄ±Ã§ ============== #
st.title("âš¡ Tetkik Analiz â€” Ã‡oklu Dosya (Optimize)")
st.caption("BÃ¼yÃ¼k veri ve Ã§oklu dosya iÃ§in hÄ±zlandÄ±rÄ±lmÄ±ÅŸ sÃ¼rÃ¼m.")

uploads = st.file_uploader("Excel dosyalarÄ± (.xlsx, .xls) â€” Ã‡oklu seÃ§im", type=["xlsx", "xls"], accept_multiple_files=True)

use_polars = st.checkbox("Polars hÄ±zlandÄ±rmayÄ± dene (kuruluysa)", value=HAS_POLARS and True,
                         help="Polars kurulu deÄŸilse otomatik devre dÄ±ÅŸÄ± kalÄ±r.")

if not uploads:
    st.info("Birden Ã§ok dosyayÄ± aynÄ± anda seÃ§in. Ã–rn: 12 dosya.")
    st.stop()

with st.spinner("Dosyalar okunuyor..."):
    results = read_many_excels(uploads)

frames = []
skipped = []
for name, tmp, err in results:
    if err:
        skipped.append((name, f"Okuma hatasÄ±: {err}"))
        continue
    miss = check_columns(tmp)
    if miss:
        skipped.append((name, f"Eksik sÃ¼tun: {miss}"))
        continue
    tmp["SOURCE_FILE"] = name
    frames.append(tmp)

if skipped:
    for nm, msg in skipped:
        st.warning(f"'{nm}' atlandÄ± â†’ {msg}")

if not frames:
    st.error("Uygun veri iÃ§eren dosya bulunamadÄ±.")
    st.stop()

# BirleÅŸtir
df = pd.concat(frames, ignore_index=True)
df = downcast_df(df)

# Polars'a Ã§evir (opsiyonel)
if use_polars and HAS_POLARS:
    try:
        pl_df = pl.from_pandas(df)
    except Exception:
        use_polars = False
        pl_df = None
else:
    pl_df = None

# ================= Filtreler ================= #
left, right = st.columns([3, 2])
with left:
    unique_tests = sorted([str(x) for x in df["TETKIK_ISMI"].dropna().unique()])
    default_pick = unique_tests[:5] if len(unique_tests) > 5 else unique_tests[:1]
    selected_tests = st.multiselect("Analiz edilecek tetkikler", options=unique_tests, default=default_pick)
with right:
    sexes = [str(x) for x in df["CINSIYET"].dropna().unique()]
    chosen_sex = st.multiselect("Cinsiyet filtresi", options=sexes, default=sexes)
    files = [str(x) for x in df["SOURCE_FILE"].dropna().unique()]
    chosen_files = st.multiselect("Dosya filtresi", options=files, default=files)

work = df.copy()
if chosen_sex:
    work = work[work["CINSIYET"].astype(str).isin(chosen_sex)]
if chosen_files:
    work = work[work["SOURCE_FILE"].astype(str).isin(chosen_files)]
if selected_tests:
    work = work[work["TETKIK_ISMI"].astype(str).isin(selected_tests)]

# ================= VARYANT Ã–ZETLERÄ° (Anormal Hb / Talasemi HPLC) ================= #
# Bu blok iki tablo Ã¼retir:
# 1) "â™€/â™‚ MeanÂ±SD" : SeÃ§ilen varyant iÃ§in Female/Male Ã¶zet tablosu (Mean Â± SD + ref aralÄ±ÄŸÄ±)
# 2) "Varyant Matrisi": SÃ¼tunlarda varyantlar, satÄ±rlarda parametreler (sayÄ± deÄŸerleri = mean)

import re
import pandas as pd
import numpy as np
import streamlit as st

# --- YardÄ±mcÄ±: sayÄ±sal dÃ¶nÃ¼ÅŸÃ¼m (dataset'te zaten varsa onu kullanÄ±r)
def _num(s):
    return pd.to_numeric(
        str(s).replace(",", ".").replace(" ", ""),
        errors="coerce"
    )

# --- Normalizasyon fonksiyonlarÄ± (Anormal Hb / HPLC iÃ§in) ---
def normalize_anormal_hb(x: str):
    if x is None: return None
    s = str(x).upper().replace("Ä°","I").strip()
    if re.search(r"\bHBS\b", s): return "HbS"
    if re.search(r"\bHBC\b", s): return "HbC"
    if re.search(r"\bHBD\b", s): return "HbD"
    if re.search(r"\bHBE\b", s): return "HbE"
    if re.search(r"DELTA ?BETA|Î”Î²|DBETA", s): return "Î´Î²-thal"
    if re.search(r"S-?BETA|S ?Î²", s): return "Hb S-Î²-thal"
    if re.search(r"F\b", s): return "HbFâ†‘"
    if re.search(r"A2|HBA2", s): return "HbA2â†‘"
    if re.search(r"NORMAL|NEG", s): return "Normal"
    return s or None

def normalize_talasemi(x: str):
    if x is None: return None
    s = str(x).upper().replace("Ä°","I").strip()
    if re.search(r"MAJOR", s): return "Major"
    if re.search(r"MINOR", s): return "Minor"
    if re.search(r"TA[IS]IY", s): return "TaÅŸÄ±yÄ±cÄ±"
    if re.search(r"HETERO", s): return "Heterozigot"
    if re.search(r"HOMO", s): return "Homozigot"
    if re.search(r"NORMAL|NEG", s): return "Normal"
    return s or None

# --- 1) Varyant etiketi Ã¼ret (aynÄ± PROTOKOL_NO iÃ§indeki bulgulardan tek etiket) ---
variant_rows = work[
    work["TETKIK_ISMI"].isin(["Anormal Hb/", "Talasemi(HPLC) (A0)/"])
].copy()

def _pick_variant(g):
    # Ã–ncelik sÄ±rasÄ± (patolojik olanlar Ã¶nce)
    priority = ["HbS","HbC","HbD","HbE","Hb S-Î²-thal","Î´Î²-thal",
                "Major","Minor","TaÅŸÄ±yÄ±cÄ±","Heterozigot","Homozigot",
                "HbA2â†‘","HbFâ†‘","Normal"]
    tags = []
    for _, r in g.iterrows():
        val = str(r["TEST_DEGERI"])
        if r["TETKIK_ISMI"] == "Anormal Hb/":
            v = normalize_anormal_hb(val)
        else:
            v = normalize_talasemi(val)
        if v: tags.append(v)
    if not tags: return None
    # Ã¶nceliÄŸe gÃ¶re seÃ§
    for p in priority:
        if p in tags: return p
    return tags[0]

if not variant_rows.empty:
    var_map = (variant_rows
               .groupby("PROTOKOL_NO")
               .apply(_pick_variant)
               .rename("VARIANT")
               .reset_index())
    work = work.merge(var_map, on="PROTOKOL_NO", how="left")
else:
    work["VARIANT"] = None

# --- Analiz edilecek parametre eÅŸlemesi (TETKIK_ISMI â†’ gÃ¶rÃ¼nÃ¼r ad) ---
PARAMS = {
    "Hemogram/HGB": "Hb (g/dL)",
    "Hemogram/HCT": "HCT (%)",
    "Hemogram/RBC": "RBC (Ã—10â¶)",
    "Hemogram/RDW": "RDW (%)",
    "Hemogram/MCV": "MCV (fL)",
    "Hemogram/MCH": "MCH (pg)",
    "Hemogram/MCHC": "MCHC (g/dL)",
    "Talasemi(HPLC) (A0)/": "HbA0/HPLC*",
    "HbA": "HbA (%)",
    "HbA2": "HbAâ‚‚ (%)",
    "HbF": "Hb F (%)",
    "Anormal Hb/": "Variant (%)"
}
# (Not: HbA, HbA2, HbF iÃ§in TETKIK_ISMI adlarÄ±n datasetinde nasÄ±l geÃ§tiÄŸine gÃ¶re yukarÄ±yÄ± dÃ¼zenleyebilirsin.)

REFS = {
    "Hb (g/dL)": "F: 11â€“15; M: 12â€“17",
    "HCT (%)":   "F: 36â€“46; M: 40â€“53",
    "RBC (Ã—10â¶)": "F: 3.9â€“5.6; M: 4.5â€“6.0",
    "RDW (%)":   "11â€“16",
    "MCV (fL)":  "80â€“100",
    "MCH (pg)":  "27â€“34",
    "MCHC (g/dL)": "32â€“36",
    "HbA (%)":   "94â€“98",
    "HbAâ‚‚ (%)":  "2â€“3.5",
    "Hb F (%)":  "0â€“2",
}

# --- YardÄ±mcÄ±: belli parametrenin numeric serisini getir ---
def get_param_series(df, tetkik_key):
    s = df.loc[df["TETKIK_ISMI"] == tetkik_key, "TEST_DEGERI"]
    return s.astype(str).map(_num)

# ============ TABLO #1: SeÃ§ilen VARYANT iÃ§in Female / Male MeanÂ±SD ============ #
st.header("ğŸ“‹ Varyant Ã–zet Tablosu â€” â™€/â™‚ Mean Â± SD")
variant_opts = ["(TÃ¼mÃ¼)"] + sorted([v for v in work["VARIANT"].dropna().unique()])
v_choice = st.selectbox("Varyant seÃ§:", variant_opts, index=0)

base = work.copy()
if v_choice != "(TÃ¼mÃ¼)":
    base = base[base["VARIANT"] == v_choice]

def _mean_sd_str(x):
    x = pd.to_numeric(x, errors="coerce").dropna()
    return "â€”" if x.empty else f"{x.mean():.2f} Â± {x.std(ddof=1):.2f}"

rows_fm = []
for tetkik_key, display_name in PARAMS.items():
    # sadece mevcut olanlarÄ± yaz
    s_all = base.loc[base["TETKIK_ISMI"] == tetkik_key, ["TEST_DEGERI", "CINSIYET"]]
    if s_all.empty: 
        continue
    s_all["val"] = s_all["TEST_DEGERI"].astype(str).map(_num)
    f = s_all.loc[s_all["CINSIYET"].astype(str).str.lower().str.startswith(("k","f")), "val"]
    m = s_all.loc[s_all["CINSIYET"].astype(str).str.lower().str.startswith(("e","m")), "val"]
    rows_fm.append({
        "Parameter": display_name,
        "Female (Mean Â± SD)": _mean_sd_str(f),
        "Male (Mean Â± SD)": _mean_sd_str(m),
        "Reference range": REFS.get(display_name, "â€”")
    })

table_fm = pd.DataFrame(rows_fm)
st.dataframe(table_fm, use_container_width=True)
st.download_button("â¬‡ï¸ Tablo #1 (CSV)", data=table_fm.to_csv(index=False).encode("utf-8-sig"),
                   file_name="varyant_ozet_female_male.csv", mime="text/csv")

# ============ TABLO #2: VARYANT MATRÄ°SÄ° (SÃ¼tun = Varyant, SatÄ±r = Parametre) ============ #
st.header("ğŸ“Š Varyant Matrisi â€” Parametre OrtalamalarÄ±")

# Hangi varyantlar sÃ¼tun olsun?
variant_cols = sorted([v for v in work["VARIANT"].dropna().unique()])
if not variant_cols:
    st.info("Varyant etiketi bulunamadÄ± (Anormal Hb / Talasemi HPLC satÄ±rlarÄ± yok).")
else:
    # SatÄ±rlarÄ± oluÅŸtur
    matrix_rows = []
    for tetkik_key, display_name in PARAMS.items():
        # Her varyant iÃ§in mean hesapla
        row = {"Parameter": display_name}
        any_present = False
        for v in variant_cols:
            dfv = work[(work["VARIANT"] == v) & (work["TETKIK_ISMI"] == tetkik_key)]
            if not dfv.empty:
                vals = dfv["TEST_DEGERI"].astype(str).map(_num).dropna()
                row[v] = round(vals.mean(), 2) if not vals.empty else np.nan
                any_present = True
            else:
                row[v] = np.nan
        if any_present:
            matrix_rows.append(row)

    # F/M sayÄ±sÄ±nÄ± ayrÄ± satÄ±r olarak ekle
    fm_row = {"Parameter": "Gender (F/M)"}
    for v in variant_cols:
        sub_v = work[work["VARIANT"] == v]
        f = (sub_v["CINSIYET"].astype(str).str.lower().str.startswith(("k","f"))).sum()
        m = (sub_v["CINSIYET"].astype(str).str.lower().str.startswith(("e","m"))).sum()
        fm_row[v] = f"{f}/{m}"
    matrix_rows.insert(0, fm_row)

    # YaÅŸ varsa (AGE/YAS) onu da ekle (opsiyonel; yoksa atlanÄ±r)
    if "AGE" in work.columns or "YAS" in work.columns:
        age_col = "AGE" if "AGE" in work.columns else "YAS"
        age_row = {"Parameter": "Age (years)"}
        for v in variant_cols:
            vals = pd.to_numeric(work.loc[work["VARIANT"] == v, age_col], errors="coerce").dropna()
            age_row[v] = round(vals.mean(), 2) if not vals.empty else np.nan
        matrix_rows.insert(1, age_row)

    table_var = pd.DataFrame(matrix_rows)
    st.dataframe(table_var, use_container_width=True)
    st.download_button("â¬‡ï¸ Tablo #2 (CSV)", data=table_var.to_csv(index=False).encode("utf-8-sig"),
                       file_name="varyant_matrisi.csv", mime="text/csv")

# ================= Ã–n-izleme & MÃ¼dahale: Metinden SayÄ±ya ================= #
import re
import numpy as np
import pandas as pd
import streamlit as st

# --- YardÄ±mcÄ±lar (esnek sayÄ± Ã§Ã¶zÃ¼cÃ¼) ---
def _dec_fix(x: str) -> str:
    s = x.replace("\xa0", " ").strip()
    # hem '.' hem ',' varsa: sondaki ayraÃ§ ondalÄ±k, diÄŸerleri binlik sayÄ±lÄ±r
    if "," in s and "." in s:
        last = max(s.rfind(","), s.rfind("."))
        dec = s[last]
        s = re.sub(r"[.,](?=\d{3}\b)", "", s)  # binlikleri at
        s = s.replace(dec, ".")
    elif "," in s:
        s = s.replace(".", "")         # olasÄ± binlik noktalarÄ±
        s = s.replace(",", ".")        # ondalÄ±k virgÃ¼l â†’ nokta
    else:
        s = re.sub(r"\.(?=\d{3}\b)", "", s)  # binlik noktayÄ± at
    return s

def smart_number(text: str):
    """Ã–neri Ã¼retir (float veya None). Birimleri, %, < >, aralÄ±klarÄ± yakalar."""
    if text is None: 
        return None
    s = str(text).strip().lower()
    if s in {"", "nan", "na", "n/a", "yok", "boÅŸ", "empty", "nd"}:
        return None
    if s in {"pozitif", "+", "positive", "pos"}: return 1.0
    if s in {"negatif", "-", "negative", "neg"}: return 0.0

    # yÃ¼zde (15% â†’ 15)
    s = s.replace("%", " ")

    # eÅŸitsizlikler (<, â‰¤, >, â‰¥) â†’ sÄ±nÄ±r deÄŸer (isteÄŸe gÃ¶re geliÅŸtirebiliriz)
    m_ineq = re.match(r"^\s*([<>]=?)\s*([0-9.,]+)", s)
    if m_ineq:
        op, num = m_ineq.groups()
        try: v = float(_dec_fix(num))
        except: v = None
        return v

    # aralÄ±klar (12â€“14, 12-14) â†’ ortalama
    m_rng = re.match(r"^\s*([+-]?\d[\d.,]*)\s*[-â€“â€”]\s*([+-]?\d[\d.,]*)", s)
    if m_rng:
        a, b = m_rng.groups()
        try:
            a = float(_dec_fix(a)); b = float(_dec_fix(b))
            return (a + b) / 2.0
        except:
            return None

    # metin iÃ§indeki ilk sayÄ±yÄ± Ã§ek (12,3 g/dL vb.)
    m_any = re.search(r"[+-]?\d[\d.,]*", s)
    if m_any:
        try: return float(_dec_fix(m_any.group(0)))
        except: return None

    return None

# --- Problem yakalama: Ã–neri + iÅŸaretleme ---
orig = work["TEST_DEGERI"].astype(str)
suggested = orig.map(smart_number)

# â€œproblemliâ€ kriteri: numeric'e Ã§evrilemiyor ya da metinde iÅŸaret/harf/aralÄ±k var
is_categorical_row = work["TETKIK_ISMI"].astype(str).isin(CATEGORICAL_TESTS)
mask_problem = (
    (~is_categorical_row) & (
        suggested.isna() |
        orig.str.contains(r"[A-Za-z%<>]|[-â€“â€”].*[-â€“â€”]", regex=True)
    )
)

# Ä°nceleme tablosu: orijinal + Ã¶neri + dÃ¼zenlenebilir hedef
preview = work.loc[mask_problem, [
    "TETKIK_ISMI", "CINSIYET", "PROTOKOL_NO", "TCKIMLIK_NO", "TEST_DEGERI"
]].copy()

preview = preview.reset_index().rename(columns={"index": "__ROW_ID__"})
preview["SUGGESTED"] = suggested.loc[preview["__ROW_ID__"]].values

st.header("ğŸ§¹ Problemli DeÄŸerler â€” Ã–n-izleme & MÃ¼dahale")
st.caption("AÅŸaÄŸÄ±da metin iÃ§erikli/sorunlu tÃ¼m deÄŸerler listelenir. 'CLEAN_VALUE' sÃ¼tununu elle dÃ¼zeltebilirsin.")

# DÃ¼zenlenebilir sÃ¼tun: CLEAN_VALUE (baÅŸlangÄ±Ã§ta Ã¶neri)
preview["CLEAN_VALUE"] = preview["SUGGESTED"]

edited = st.data_editor(
    preview,
    use_container_width=True,
    num_rows="fixed",
    column_config={
        "__ROW_ID__": st.column_config.NumberColumn(label="RowID", help="Orijinal satÄ±r indeksi", disabled=True),
        "TEST_DEGERI": st.column_config.TextColumn(label="ORIGINAL", help="Ham deÄŸer", disabled=True),
        "SUGGESTED": st.column_config.NumberColumn(label="Ã–NERÄ° (otomatik)", help="AlgoritmanÄ±n Ã¶nerdiÄŸi", disabled=True),
        "CLEAN_VALUE": st.column_config.NumberColumn(label="CLEAN_VALUE (elle dÃ¼zenle)", help="BurayÄ± istediÄŸin gibi deÄŸiÅŸtir"),
    },
    hide_index=True
)

col_apply, col_opts = st.columns([1,1])
with col_apply:
    apply_now = st.button("âœ… DÃ¼zenlemeleri uygula (TEST_DEGERI_CLEAN)")

with col_opts:
    overwrite_main = st.checkbox("TEST_DEGERI sÃ¼tununu CLEAN_VALUE ile deÄŸiÅŸtir", value=False)

if apply_now:
    # Son kullanÄ±cÄ±nÄ±n girdiklerini orijinal work'e geri yaz
    updates = edited[["__ROW_ID__", "CLEAN_VALUE"]].dropna(subset=["__ROW_ID__"])
    work.loc[updates["__ROW_ID__"].values, "TEST_DEGERI_CLEAN"] = updates["CLEAN_VALUE"].values

    if overwrite_main:
        work.loc[updates["__ROW_ID__"].values, "TEST_DEGERI"] = updates["CLEAN_VALUE"].values

    st.success(
        f"GÃ¼ncellendi: {updates['__ROW_ID__'].nunique():,} satÄ±r iÃ§in CLEAN_VALUE uygulandÄ±. "
        f"{'TEST_DEGERI de gÃ¼ncellendi.' if overwrite_main else 'TEST_DEGERI_CLEAN sÃ¼tunu oluÅŸturuldu/gÃ¼ncellendi.'}"
    )
    st.download_button(
        "â¬‡ï¸ Temiz/duzeltilmiÅŸ veriyi indir (CSV)",
        data=work.to_csv(index=False).encode("utf-8-sig"),
        file_name="temizlenmis_veri.csv",
        mime="text/csv"
    )



# ================= Genel Bilgiler ================= #
st.subheader("ğŸ” Genel Bilgiler (BirleÅŸtirilmiÅŸ)")
c1, c2, c3, c4, c5 = st.columns(5)
c1.metric("Toplam SatÄ±r", f"{len(df):,}")
c2.metric("Benzersiz TCKIMLIK_NO", f"{df['TCKIMLIK_NO'].nunique():,}")
c3.metric("Benzersiz Tetkik", f"{df['TETKIK_ISMI'].nunique():,}")
c4.metric("Benzersiz Cinsiyet", f"{df['CINSIYET'].nunique():,}")
c5.metric("Dosya SayÄ±sÄ±", f"{df['SOURCE_FILE'].nunique():,}")

with st.expander("Ham Veri Ã–n Ä°zleme (limitli)"):
    st.dataframe(work.head(DISPLAY_LIMIT), use_container_width=True)
    st.caption(f"YalnÄ±zca ilk {DISPLAY_LIMIT} satÄ±r gÃ¶rÃ¼ntÃ¼lenir.")

# ================= HÄ±zlÄ± Ã–zetler ================= #
st.header("âš™ï¸ HÄ±zlÄ± Ã–zet ve KÄ±rÄ±lÄ±mlar")
colA, colB = st.columns(2)
with colA:
    st.write("**Cinsiyete GÃ¶re TanÄ±mlayÄ±cÄ±lar (SeÃ§imdeki veri)**")
    if use_polars and pl_df is not None:
        pl_sub = pl.from_pandas(work[["CINSIYET", "TEST_DEGERI"]].copy())
        grp = (pl_sub
               .groupby("CINSIYET")
               .agg([pl.len().alias("count"),
                     pl.col("TEST_DEGERI").mean().alias("mean"),
                     pl.col("TEST_DEGERI").std().alias("std"),
                     pl.col("TEST_DEGERI").min().alias("min"),
                     pl.col("TEST_DEGERI").median().alias("median"),
                     pl.col("TEST_DEGERI").quantile(0.25, "nearest").alias("q1"),
                     pl.col("TEST_DEGERI").quantile(0.75, "nearest").alias("q3"),
                     pl.col("TEST_DEGERI").max().alias("max")])
               .to_pandas())
        st.dataframe(grp, use_container_width=True)
    else:
        grp = (work.groupby("CINSIYET", dropna=False)["TEST_DEGERI"]
               .agg(["count", "mean", "std", "min", "median", "max"]).reset_index())
        st.dataframe(grp, use_container_width=True)

with colB:
    st.write("**Dosyaya GÃ¶re SatÄ±r & Hasta & Tetkik SayÄ±sÄ±**")
    per_file = work.groupby("SOURCE_FILE").agg(
        N=("PROTOKOL_NO", "size"),
        Hasta_Sayisi=("TCKIMLIK_NO", "nunique"),
        Tetkik_Sayisi=("TETKIK_ISMI", "nunique")
    ).reset_index()
    st.dataframe(per_file, use_container_width=True)
    export_df(per_file, "dosya_bazinda_ozet_filtreli.csv")

# ================= Tetkik BazlÄ± Analiz ================= #
st.header("ğŸ“Š Tetkik BazlÄ± Analiz (SeÃ§im)")

results_rows = []

for test_name in selected_tests:
    sub = work[work["TETKIK_ISMI"].astype(str) == test_name].copy()
    if sub.empty:
        continue

    st.subheader(f"ğŸ§· {test_name}")
        # --- Kategorik mi? ---
    is_categorical = test_name in CATEGORICAL_TESTS
    if not is_categorical:
        vals = sub["TEST_DEGERI"].astype(str)
        num_ok = pd.to_numeric(vals.str.replace(",", ".", regex=False), errors="coerce").notna().mean()
        if num_ok < 0.6:
            is_categorical = True

    if is_categorical:
        st.info("Bu tetkik kategorik olarak deÄŸerlendirildi (frekans analizi yapÄ±lacak).")
    # ----- VARYANT POZÄ°TÄ°F FÄ°LTRESÄ°: sadece >0 deÄŸerler dahil olsun -----
    positive_only = st.checkbox(
        f"â€˜{test_name}â€™ iÃ§in sadece > 0 deÄŸerleri dahil et (varyant-pozitif filtre)",
        value=(test_name in VARIANT_NUMERIC_TESTS),
        key=f"pos_only_{test_name}"
    )

    sub_num = sub.copy()
    sub_num["__VAL_NUM__"] = (
        sub_num["TEST_DEGERI"].astype(str)
        .str.replace(",", ".", regex=False)
        .str.replace(" ", "", regex=False)
    )
    sub_num["__VAL_NUM__"] = pd.to_numeric(sub_num["__VAL_NUM__"], errors="coerce")

    if positive_only:
        sub_num = sub_num[sub_num["__VAL_NUM__"] > 0]
        if sub_num.empty:
            st.warning("Bu tetkikte (>0) pozitif satÄ±r bulunamadÄ±.")

        # ====== Normalizasyon FonksiyonlarÄ± ====== #
        import re

        def normalize_blood_group(x):
            if not isinstance(x, str):
                return None
            s = x.upper().replace("Ä°", "I").strip()
            abo = None
            if re.search(r"\bAB\b", s): abo = "AB"
            elif re.search(r"\bA\b", s): abo = "A"
            elif re.search(r"\bB\b", s): abo = "B"
            elif re.search(r"\b0\b|\bO\b", s): abo = "O"
            rh = "Rh(+)" if re.search(r"(\+|POS|POZ|RH\+)", s) else "Rh(-)" if re.search(r"(\-|NEG)", s) else ""
            return (abo + " " + rh).strip() if abo else s or None

        def normalize_anormal_hb(x):
            if not isinstance(x, str):
                return None
            s = x.upper().replace("Ä°", "I").strip()
            # Hb varyantlarÄ±nÄ± tek forma getir
            if re.search(r"HBS", s): return "HbS"
            if re.search(r"HBC", s): return "HbC"
            if re.search(r"HBA2|A2", s): return "HbA2â†‘"
            if re.search(r"HBF", s): return "HbFâ†‘"
            if re.search(r"NORMAL", s): return "Normal"
            if re.search(r"UNK|BILINM", s): return "Bilinmiyor"
            return s

        def normalize_talasemi(x):
            if not isinstance(x, str):
                return None
            s = x.upper().replace("Ä°", "I").strip()
            if re.search(r"TA[IÄ°]SIY", s): return "TaÅŸÄ±yÄ±cÄ±"
            if re.search(r"MINOR", s): return "Minor"
            if re.search(r"MAJOR", s): return "Major"
            if re.search(r"HETERO", s): return "Heterozigot"
            if re.search(r"HOMO", s): return "Homozigot"
            if re.search(r"NORMAL|NEG", s): return "Normal"
            return s

        # ====== Hangi fonksiyon kullanÄ±lacak? ====== #
        if test_name == "Kan Grubu/":
            cat_series = sub["TEST_DEGERI"].map(normalize_blood_group)
        elif test_name == "Anormal Hb/":
            cat_series = sub["TEST_DEGERI"].map(normalize_anormal_hb)
        elif test_name == "Talasemi(HPLC) (A0)/":
            cat_series = sub["TEST_DEGERI"].map(normalize_talasemi)
        else:
            cat_series = sub["TEST_DEGERI"].astype(str).str.strip()

        sub_cat = sub.assign(__CAT__=cat_series)

        # ====== Frekans ve cinsiyet kÄ±rÄ±lÄ±mÄ± ====== #
        freq_all = (
            sub_cat["__CAT__"]
            .value_counts(dropna=False)
            .rename_axis("Kategori")
            .to_frame("N")
            .reset_index()
        )
        freq_all["%"] = (freq_all["N"] / freq_all["N"].sum() * 100).round(2)

        freq_by_sex = (
            sub_cat.pivot_table(index="__CAT__", columns="CINSIYET",
                                values="PROTOKOL_NO", aggfunc="count", fill_value=0)
            .astype(int).reset_index().rename(columns={"__CAT__": "Kategori"})
        )

        # ====== Ki-kare testi ====== #
        chi2_msg = "Ki-kare uygulanamadÄ±."
        try:
            from scipy.stats import chi2_contingency
            cont = freq_by_sex.drop(columns=["Kategori"]).values
            if cont.sum() > 0 and cont.shape[1] > 1:
                chi2, p, dof, _ = chi2_contingency(cont)
                chi2_msg = f"Chi-square: Ï‡Â²={chi2:.2f}, df={dof}, p={p:.4g}"
        except Exception as e:
            chi2_msg = f"Hata: {e}"

        tabs = st.tabs(["Frekans", "Cinsiyet DaÄŸÄ±lÄ±mÄ±", "Ä°statistik"])
        with tabs[0]:
            st.dataframe(freq_all, use_container_width=True)
        with tabs[1]:
            st.dataframe(freq_by_sex, use_container_width=True)
        with tabs[2]:
            st.info(chi2_msg)

        results_rows.append({
            "TETKIK_ISMI": test_name,
            "N": int(freq_all["N"].sum()),
            "Mean": None, "Median": None, "Std": None, "Min": None, "Q1": None, "Q3": None, "Max": None,
            "Normalite": "â€”",
            "Test": chi2_msg
        })
        continue  # SayÄ±sal analize geÃ§me


    # TanÄ±mlayÄ±cÄ±lar
    stats_overall = descr_stats_fast(sub["TEST_DEGERI"])
    normal_flag = normality_flag(sub["TEST_DEGERI"])

    # Cinsiyet kÄ±rÄ±lÄ±mÄ± (vektÃ¶rize)
    by_sex = (sub.groupby("CINSIYET", dropna=False)["TEST_DEGERI"]
              .agg(count="count", mean="mean", std="std", min="min", median="median", max="max")).reset_index()

    # Dosya kÄ±rÄ±lÄ±mÄ± (vektÃ¶rize)
    by_file = (sub.groupby("SOURCE_FILE", dropna=False)["TEST_DEGERI"]
               .agg(count="count", mean="mean", std="std", min="min", median="median", max="max")).reset_index()

    # Test
    msg, test_info = nonparametric_test_by_group(sub, "TEST_DEGERI", "CINSIYET")

    results_rows.append({
        "TETKIK_ISMI": test_name,
        "N": stats_overall["count"],
        "Mean": stats_overall["mean"],
        "Median": stats_overall["median"],
        "Std": stats_overall["std"],
        "Min": stats_overall["min"],
        "Q1": stats_overall["q1"],
        "Q3": stats_overall["q3"],
        "Max": stats_overall["max"],
        "Normalite": normal_flag,
        "Test": msg
    })

    # Sekmeler; grafikler isteÄŸe baÄŸlÄ±
    tabs = st.tabs(["TanÄ±mlayÄ±cÄ±", "Cinsiyet", "Dosya", "Ä°statistiksel Test", "Histogram", "Boxplot"])
    with tabs[0]:
        st.table(pd.DataFrame([stats_overall]))
    with tabs[1]:
        st.dataframe(by_sex, use_container_width=True)
    with tabs[2]:
        st.dataframe(by_file, use_container_width=True)
    with tabs[3]:
        st.info(msg)
    with tabs[4]:
        if st.checkbox(f"Histogram gÃ¶ster ({test_name})", value=False):
            make_hist(sub, "TEST_DEGERI", bins=30, title=f"{test_name} - Histogram")
    with tabs[5]:
        if st.checkbox(f"Boxplot gÃ¶ster ({test_name})", value=False):
            make_boxplot(sub, "CINSIYET", "TEST_DEGERI", title=f"{test_name} - Cinsiyete GÃ¶re Boxplot")

# Toplu Ã¶zet
if results_rows:
    st.header("ğŸ§¾ Toplu Ã–zet Tablosu (SeÃ§ili Tetkikler)")
    res_df = pd.DataFrame(results_rows)
    st.dataframe(res_df, use_container_width=True)
    export_df(res_df, name="tetkik_ozet.csv")

# ================= Otomatik Rapor (TÃ¼m Tetkikler) ================= #
st.header("ğŸ“‘ Otomatik Rapor (TÃ¼m Tetkikler)")
if st.button("Raporu Ã¼ret (tam veri)"):
    rows = []
    for t in sorted(df["TETKIK_ISMI"].dropna().astype(str).unique()):
        sub = df[df["TETKIK_ISMI"].astype(str) == t].copy()
        sub["TEST_DEGERI"] = pd.to_numeric(sub["TEST_DEGERI"], errors="coerce")
        sub = sub.dropna(subset=["TEST_DEGERI"])
        if sub.empty:
            continue
        stats_overall = descr_stats_fast(sub["TEST_DEGERI"])
        msg, _ = nonparametric_test_by_group(sub, "TEST_DEGERI", "CINSIYET")
        rows.append({
            "TETKIK_ISMI": t,
            "N": stats_overall["count"],
            "Mean": stats_overall["mean"],
            "Median": stats_overall["median"],
            "Std": stats_overall["std"],
            "Min": stats_overall["min"],
            "Q1": stats_overall["q1"],
            "Q3": stats_overall["q3"],
            "Max": stats_overall["max"],
            "Normalite": normality_flag(sub["TEST_DEGERI"]),
            "Test": msg
        })
    if rows:
        rpt = pd.DataFrame(rows)
        st.success("Rapor hazÄ±rlandÄ±.")
        st.dataframe(rpt, use_container_width=True)
        export_df(rpt, name="tum_tetkikler_rapor.csv")
    else:
        st.warning("Rapor iÃ§in uygun veri bulunamadÄ±.")

st.caption("Performans ipuÃ§larÄ±: Ã‡ok dosya yÃ¼klerken Polars seÃ§eneÄŸini aÃ§Ä±n, grafikleri ihtiyaÃ§ duydukÃ§a gÃ¶sterin, bÃ¼yÃ¼k tablolarÄ± CSV olarak indirip lokal inceleyin.")
'''

with open('app.py', 'w', encoding='utf-8') as f:
    f.write(app_code)

'/mnt/data/app_optimized.py'
# ================= Klinik Tablo (Î²-talasemi tarzÄ±) ================= #
st.header("ğŸ“‹ Klinik Tablo â€” Hematolojik Bulgular (Otomatik)")

src_choice = st.radio(
    "Veri kaynaÄŸÄ±",
    ["SeÃ§imdeki veri (work)", "TÃ¼m veri (df)"],
    index=0,
    horizontal=True
)
base = work.copy() if src_choice.startswith("SeÃ§imdeki") else df.copy()

# Hedef parametreler ve referans aralÄ±klarÄ± (gerekirse dÃ¼zenleyebilirsin)
params = [
    ("Age (years)", None),   # YaÅŸ yoksa otomatik boÅŸ kalÄ±r
    ("Hb (g/dL)", "Hb"),     # (TETKIK_ISMI'ndeki ad)
    ("HCT (%)", "HCT"),
    ("RBC (Ã—10â¶)", "RBC"),
    ("RDW (%)", "RDW"),
    ("MCV (fL)", "MCV"),
    ("MCH (pg)", "MCH"),
    ("MCHC (g/dL)", "MCHC"),
    ("HbA (%)", "HbA"),
    ("HbAâ‚‚ (%)", "HbA2"),
    ("Hb F (%)", "HbF"),
]

ref_ranges = {
    "Hb (g/dL)": "F: 11â€“15; M: 12â€“17",
    "HCT (%)":   "F: 36â€“46; M: 40â€“53",
    "RBC (Ã—10â¶)": "F: 3.9â€“5.6; M: 4.5â€“6.0",
    "RDW (%)":   "11â€“16",
    "MCV (fL)":  "80â€“100",
    "MCH (pg)":  "27â€“34",
    "MCHC (g/dL)": "32â€“36",
    "HbA (%)":   "94â€“98",
    "HbAâ‚‚ (%)":  "2â€“3.5",
    "Hb F (%)":  "0â€“2",
    "Age (years)": "â€”",
}

# Cinsiyet normalizasyonu
sex_map = {
    "e": "Male", "erkek": "Male", "m": "Male", "male": "Male",
    "k": "Female","kadÄ±n":"Female","f":"Female","female":"Female"
}
base["__SEX__"] = (
    base["CINSIYET"].astype(str).str.strip().str.lower().map(sex_map)
)
# TEST_DEGERI sayÄ±sal gÃ¼vence
base["__VAL__"] = pd.to_numeric(
    base["TEST_DEGERI"].astype(str).str.replace(",", ".", regex=False),
    errors="coerce"
)

def fmt_mean_sd(s: pd.Series, nd=2):
    s = pd.to_numeric(s, errors="coerce").dropna()
    if len(s) == 0:
        return "â€”"
    return f"{s.mean():.{nd}f} Â± {s.std(ddof=1):.{nd}f}"

rows = []
for label, tetkik_ismi in params:
    # Age yoksa "â€”" bÄ±rak (datasetinde AGE sÃ¼tunu varsa 'AGE'â†’numeric yapÄ±p buraya entegre edebilirsin)
    if tetkik_ismi is None:
        female = "â€”"
        male = "â€”"
    else:
        sub = base[base["TETKIK_ISMI"].astype(str) == tetkik_ismi].copy()
        female = fmt_mean_sd(sub.loc[sub["__SEX__"]=="Female", "__VAL__"])
        male   = fmt_mean_sd(sub.loc[sub["__SEX__"]=="Male", "__VAL__"])

    rows.append({
        "Parameter": label,
        "Female (Mean Â± SD)": female,
        "Male (Mean Â± SD)": male,
        "Reference range": ref_ranges.get(label, "â€”")
    })

table_df = pd.DataFrame(rows)

# GÃ¶rÃ¼ntÃ¼le + indir
st.dataframe(table_df, use_container_width=True)
csv_bytes = table_df.to_csv(index=False).encode("utf-8-sig")
st.download_button("â¬‡ï¸ Tabloyu CSV indir", data=csv_bytes, file_name="klinik_tablo.csv", mime="text/csv")

st.caption(
    "Not: Cinsiyet eÅŸleÅŸtirmesi E/K/Erkek/KadÄ±n/Male/Female yazÄ±mlarÄ±nÄ± otomatik algÄ±lar. "
    "YaÅŸ (Age) veriniz yoksa satÄ±r 'â€”' kalÄ±r. Ä°stersen AGE/YAÅ sÃ¼tununu eklersen hesaplarÄ±m."
)
