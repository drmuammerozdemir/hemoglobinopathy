# Create an optimized version of the Streamlit app with performance improvements for many files.
# Key upgrades:
# - Cached, parallel file reading
# - Optional Polars backend (if installed)
# - Downcasting dtypes + categorical conversion
# - On-demand charts (to avoid rendering overhead)
# - Vectorized per-group stats via pandas agg
# - Heavier ops hidden behind expanders
# - Safer large-data display (sample/limit)

app_code = r'''
# -*- coding: utf-8 -*-
"""
ğŸ§ª Tetkik Analiz ArayÃ¼zÃ¼ â€” Ã‡oklu Dosya (Optimize)
- Ã‡oklu dosya iÃ§in hÄ±zlÄ± okuma (paralel + cache)
- Bellek optimizasyonu (downcast, categorical)
- Ä°steÄŸe baÄŸlÄ± Polars hÄ±zlandÄ±rma (kuruluysa)
- BÃ¼yÃ¼k tablolarÄ± temkinli gÃ¶sterim (Ã¶rnekleme/limit)
- Grafikler isteÄŸe baÄŸlÄ± oluÅŸturulur (butonlar/checkbox), matplotlib (renk set edilmez)
Kurulum:
    pip install streamlit pandas numpy scipy openpyxl matplotlib
(opsiyonel hÄ±zlandÄ±rma)
    pip install polars pyarrow
Ã‡alÄ±ÅŸtÄ±rma:
    streamlit run app_optimized.py
"""

import io
import math
import numpy as np
import pandas as pd
import streamlit as st
from scipy import stats
import matplotlib.pyplot as plt
from concurrent.futures import ThreadPoolExecutor

# ============== Ayarlar ============== #
st.set_page_config(page_title="Tetkik Analiz â€” Optimize", layout="wide")
REQ_COLS = ["PROTOKOL_NO", "TCKIMLIK_NO", "TETKIK_ISMI", "TEST_DEGERI", "CINSIYET"]
DISPLAY_LIMIT = 200  # BÃ¼yÃ¼k veri iÃ§in Ã¶nizleme limiti

# Polars mevcut mu?
try:
    import polars as pl
    HAS_POLARS = True
except Exception:
    HAS_POLARS = False

# ============== YardÄ±mcÄ±lar ============== #
def coerce_numeric(series: pd.Series) -> pd.Series:
    s = series.astype(str).str.replace(",", ".", regex=False).str.replace(" ", "", regex=False)
    return pd.to_numeric(s, errors="coerce")

def check_columns(df: pd.DataFrame):
    return [c for c in REQ_COLS if c not in df.columns]

def downcast_df(df: pd.DataFrame) -> pd.DataFrame:
    # PROTOKOL_NO, TCKIMLIK_NO sayÄ±ya dÃ¶nmesin (ID olabilir), diÄŸer uygun alanlarÄ± kÃ¼Ã§Ã¼lt
    # TEST_DEGERI numerik
    if "TEST_DEGERI" in df.columns:
        df["TEST_DEGERI"] = coerce_numeric(df["TEST_DEGERI"])
        df["TEST_DEGERI"] = pd.to_numeric(df["TEST_DEGERI"], errors="coerce", downcast="float")
    # Kategorik alanlar
    for col in ["TETKIK_ISMI", "CINSIYET", "SOURCE_FILE"]:
        if col in df.columns:
            df[col] = df[col].astype("category")
    return df

def descr_stats_fast(x: pd.Series) -> dict:
    x = pd.to_numeric(x, errors="coerce")
    x = x[~x.isna()]
    if x.empty:
        return {"count": 0, "mean": np.nan, "std": np.nan, "min": np.nan,
                "q1": np.nan, "median": np.nan, "q3": np.nan, "max": np.nan,
                "cv%": np.nan, "iqr": np.nan}
    q = np.percentile(x, [25, 50, 75])
    mean = float(x.mean())
    std = float(x.std(ddof=1)) if len(x) > 1 else 0.0
    cv = (std / mean) * 100 if mean != 0 else np.nan
    return {
        "count": int(x.size),
        "mean": mean,
        "std": std,
        "min": float(x.min()),
        "q1": float(q[0]),
        "median": float(q[1]),
        "q3": float(q[2]),
        "max": float(x.max()),
        "cv%": float(cv),
        "iqr": float(q[2] - q[0]),
    }

def normality_flag(x: pd.Series, alpha=0.05) -> str:
    x = pd.to_numeric(x, errors="coerce").dropna()
    if len(x) < 3:
        return "yetersiz"
    try:
        if len(x) <= 5000:
            stat, p = stats.shapiro(x)
            return "normal" if p >= alpha else "non-normal"
        else:
            res = stats.anderson(x, dist="norm")
            crit = res.critical_values[2]  # 5%
            return "normal" if res.statistic < crit else "non-normal"
    except Exception:
        return "bilinmiyor"

def nonparametric_test_by_group(df, val_col, grp_col):
    # Gruplar
    groups = [g.dropna() for _, g in df.groupby(grp_col)[val_col]]
    groups = [pd.to_numeric(g, errors="coerce").dropna() for g in groups]
    groups = [g for g in groups if len(g) > 0]
    unique_groups = df[grp_col].dropna().unique()
    unique_groups = [g for g in unique_groups if df[df[grp_col] == g][val_col].notna().sum() > 0]

    if len(unique_groups) < 2:
        return "KarÅŸÄ±laÅŸtÄ±rma iÃ§in en az 2 grup gerekli.", None

    if len(unique_groups) == 2:
        gnames = list(unique_groups)
        x = pd.to_numeric(df[df[grp_col] == gnames[0]][val_col], errors="coerce").dropna()
        y = pd.to_numeric(df[df[grp_col] == gnames[1]][val_col], errors="coerce").dropna()
        if len(x) >= 1 and len(y) >= 1:
            stat, p = stats.mannwhitneyu(x, y, alternative="two-sided")
            return f"Mannâ€“Whitney U: U={stat:.2f}, p={p:.4g} ({gnames[0]} vs {gnames[1]})", ("MWU", stat, p, gnames[0], gnames[1])
        else:
            return "Gruplarda yeterli gÃ¶zlem yok.", None
    else:
        stat, p = stats.kruskal(*groups)
        return f"Kruskalâ€“Wallis: H={stat:.2f}, p={p:.4g} (grup sayÄ±sÄ±: {len(unique_groups)})", ("KW", stat, p, unique_groups)

def make_boxplot(df, x_col, y_col, title="Kutu GrafiÄŸi"):
    valid = df[[x_col, y_col]].copy()
    valid[y_col] = pd.to_numeric(valid[y_col], errors="coerce")
    valid = valid.dropna()
    if valid.empty:
        st.info("Grafik iÃ§in yeterli veri yok.")
        return
    cats = list(valid[x_col].astype(str).unique())
    data = [valid[valid[x_col].astype(str) == c][y_col].values for c in cats]
    fig, ax = plt.subplots()
    ax.boxplot(data, labels=cats, showmeans=True)
    ax.set_title(title)
    ax.set_xlabel(x_col)
    ax.set_ylabel(y_col)
    st.pyplot(fig)

def make_hist(df, col, bins=30, title="Histogram"):
    x = pd.to_numeric(df[col], errors="coerce").dropna()
    if x.empty:
        st.info("Histogram iÃ§in yeterli veri yok.")
        return
    fig, ax = plt.subplots()
    ax.hist(x, bins=bins)
    ax.set_title(title)
    ax.set_xlabel(col)
    ax.set_ylabel("Frekans")
    st.pyplot(fig)

def export_df(df, name="export.csv"):
    csv = df.to_csv(index=False).encode("utf-8-sig")
    st.download_button("â¬‡ï¸ CSV indir", data=csv, file_name=name, mime="text/csv")

# ============== Cache'li Dosya Okuma ============== #
@st.cache_data(show_spinner=False)
def read_one_excel_cached(file_bytes: bytes, engine_hint: str = "openpyxl") -> pd.DataFrame:
    bio = io.BytesIO(file_bytes)
    return pd.read_excel(bio, engine=engine_hint)

def read_many_excels(files):
    # Paralel okuma
    def _read(upl):
        try:
            data = upl.read()  # bytes
            df = read_one_excel_cached(data)
            return (upl.name, df, None)
        except Exception as e:
            return (upl.name, None, str(e))

    out = []
    with ThreadPoolExecutor(max_workers=min(8, len(files))) as ex:
        for name, df, err in ex.map(_read, files):
            out.append((name, df, err))
    return out

# ============== UI BaÅŸlangÄ±Ã§ ============== #
st.title("âš¡ Tetkik Analiz â€” Ã‡oklu Dosya (Optimize)")
st.caption("BÃ¼yÃ¼k veri ve Ã§oklu dosya iÃ§in hÄ±zlandÄ±rÄ±lmÄ±ÅŸ sÃ¼rÃ¼m.")

uploads = st.file_uploader("Excel dosyalarÄ± (.xlsx, .xls) â€” Ã‡oklu seÃ§im", type=["xlsx", "xls"], accept_multiple_files=True)

use_polars = st.checkbox("Polars hÄ±zlandÄ±rmayÄ± dene (kuruluysa)", value=HAS_POLARS and True,
                         help="Polars kurulu deÄŸilse otomatik devre dÄ±ÅŸÄ± kalÄ±r.")

if not uploads:
    st.info("Birden Ã§ok dosyayÄ± aynÄ± anda seÃ§in. Ã–rn: 12 dosya.")
    st.stop()

with st.spinner("Dosyalar okunuyor..."):
    results = read_many_excels(uploads)

frames = []
skipped = []
for name, tmp, err in results:
    if err:
        skipped.append((name, f"Okuma hatasÄ±: {err}"))
        continue
    miss = check_columns(tmp)
    if miss:
        skipped.append((name, f"Eksik sÃ¼tun: {miss}"))
        continue
    tmp["SOURCE_FILE"] = name
    frames.append(tmp)

if skipped:
    for nm, msg in skipped:
        st.warning(f"'{nm}' atlandÄ± â†’ {msg}")

if not frames:
    st.error("Uygun veri iÃ§eren dosya bulunamadÄ±.")
    st.stop()

# BirleÅŸtir
df = pd.concat(frames, ignore_index=True)
df = downcast_df(df)

# Polars'a Ã§evir (opsiyonel)
if use_polars and HAS_POLARS:
    try:
        pl_df = pl.from_pandas(df)
    except Exception:
        use_polars = False
        pl_df = None
else:
    pl_df = None

# ================= Filtreler ================= #
left, right = st.columns([3, 2])
with left:
    unique_tests = sorted([str(x) for x in df["TETKIK_ISMI"].dropna().unique()])
    default_pick = unique_tests[:5] if len(unique_tests) > 5 else unique_tests[:1]
    selected_tests = st.multiselect("Analiz edilecek tetkikler", options=unique_tests, default=default_pick)
with right:
    sexes = [str(x) for x in df["CINSIYET"].dropna().unique()]
    chosen_sex = st.multiselect("Cinsiyet filtresi", options=sexes, default=sexes)
    files = [str(x) for x in df["SOURCE_FILE"].dropna().unique()]
    chosen_files = st.multiselect("Dosya filtresi", options=files, default=files)

work = df.copy()
if chosen_sex:
    work = work[work["CINSIYET"].astype(str).isin(chosen_sex)]
if chosen_files:
    work = work[work["SOURCE_FILE"].astype(str).isin(chosen_files)]
if selected_tests:
    work = work[work["TETKIK_ISMI"].astype(str).isin(selected_tests)]

# ================= Genel Bilgiler ================= #
st.subheader("ğŸ” Genel Bilgiler (BirleÅŸtirilmiÅŸ)")
c1, c2, c3, c4, c5 = st.columns(5)
c1.metric("Toplam SatÄ±r", f"{len(df):,}")
c2.metric("Benzersiz TCKIMLIK_NO", f"{df['TCKIMLIK_NO'].nunique():,}")
c3.metric("Benzersiz Tetkik", f"{df['TETKIK_ISMI'].nunique():,}")
c4.metric("Benzersiz Cinsiyet", f"{df['CINSIYET'].nunique():,}")
c5.metric("Dosya SayÄ±sÄ±", f"{df['SOURCE_FILE'].nunique():,}")

with st.expander("Ham Veri Ã–n Ä°zleme (limitli)"):
    st.dataframe(work.head(DISPLAY_LIMIT), use_container_width=True)
    st.caption(f"YalnÄ±zca ilk {DISPLAY_LIMIT} satÄ±r gÃ¶rÃ¼ntÃ¼lenir.")

# ================= HÄ±zlÄ± Ã–zetler ================= #
st.header("âš™ï¸ HÄ±zlÄ± Ã–zet ve KÄ±rÄ±lÄ±mlar")
colA, colB = st.columns(2)
with colA:
    st.write("**Cinsiyete GÃ¶re TanÄ±mlayÄ±cÄ±lar (SeÃ§imdeki veri)**")
    if use_polars and pl_df is not None:
        pl_sub = pl.from_pandas(work[["CINSIYET", "TEST_DEGERI"]].copy())
        grp = (pl_sub
               .groupby("CINSIYET")
               .agg([pl.len().alias("count"),
                     pl.col("TEST_DEGERI").mean().alias("mean"),
                     pl.col("TEST_DEGERI").std().alias("std"),
                     pl.col("TEST_DEGERI").min().alias("min"),
                     pl.col("TEST_DEGERI").median().alias("median"),
                     pl.col("TEST_DEGERI").quantile(0.25, "nearest").alias("q1"),
                     pl.col("TEST_DEGERI").quantile(0.75, "nearest").alias("q3"),
                     pl.col("TEST_DEGERI").max().alias("max")])
               .to_pandas())
        st.dataframe(grp, use_container_width=True)
    else:
        grp = (work.groupby("CINSIYET", dropna=False)["TEST_DEGERI"]
               .agg(["count", "mean", "std", "min", "median", "max"]).reset_index())
        st.dataframe(grp, use_container_width=True)

with colB:
    st.write("**Dosyaya GÃ¶re SatÄ±r & Hasta & Tetkik SayÄ±sÄ±**")
    per_file = work.groupby("SOURCE_FILE").agg(
        N=("PROTOKOL_NO", "size"),
        Hasta_Sayisi=("TCKIMLIK_NO", "nunique"),
        Tetkik_Sayisi=("TETKIK_ISMI", "nunique")
    ).reset_index()
    st.dataframe(per_file, use_container_width=True)
    export_df(per_file, "dosya_bazinda_ozet_filtreli.csv")

# ================= Tetkik BazlÄ± Analiz ================= #
st.header("ğŸ“Š Tetkik BazlÄ± Analiz (SeÃ§im)")

results_rows = []

for test_name in selected_tests:
    sub = work[work["TETKIK_ISMI"].astype(str) == test_name].copy()
    if sub.empty:
        continue

    st.subheader(f"ğŸ§· {test_name}")

    # TanÄ±mlayÄ±cÄ±lar
    stats_overall = descr_stats_fast(sub["TEST_DEGERI"])
    normal_flag = normality_flag(sub["TEST_DEGERI"])

    # Cinsiyet kÄ±rÄ±lÄ±mÄ± (vektÃ¶rize)
    by_sex = (sub.groupby("CINSIYET", dropna=False)["TEST_DEGERI"]
              .agg(count="count", mean="mean", std="std", min="min", median="median", max="max")).reset_index()

    # Dosya kÄ±rÄ±lÄ±mÄ± (vektÃ¶rize)
    by_file = (sub.groupby("SOURCE_FILE", dropna=False)["TEST_DEGERI"]
               .agg(count="count", mean="mean", std="std", min="min", median="median", max="max")).reset_index()

    # Test
    msg, test_info = nonparametric_test_by_group(sub, "TEST_DEGERI", "CINSIYET")

    results_rows.append({
        "TETKIK_ISMI": test_name,
        "N": stats_overall["count"],
        "Mean": stats_overall["mean"],
        "Median": stats_overall["median"],
        "Std": stats_overall["std"],
        "Min": stats_overall["min"],
        "Q1": stats_overall["q1"],
        "Q3": stats_overall["q3"],
        "Max": stats_overall["max"],
        "Normalite": normal_flag,
        "Test": msg
    })

    # Sekmeler; grafikler isteÄŸe baÄŸlÄ±
    tabs = st.tabs(["TanÄ±mlayÄ±cÄ±", "Cinsiyet", "Dosya", "Ä°statistiksel Test", "Histogram", "Boxplot"])
    with tabs[0]:
        st.table(pd.DataFrame([stats_overall]))
    with tabs[1]:
        st.dataframe(by_sex, use_container_width=True)
    with tabs[2]:
        st.dataframe(by_file, use_container_width=True)
    with tabs[3]:
        st.info(msg)
    with tabs[4]:
        if st.checkbox(f"Histogram gÃ¶ster ({test_name})", value=False):
            make_hist(sub, "TEST_DEGERI", bins=30, title=f"{test_name} - Histogram")
    with tabs[5]:
        if st.checkbox(f"Boxplot gÃ¶ster ({test_name})", value=False):
            make_boxplot(sub, "CINSIYET", "TEST_DEGERI", title=f"{test_name} - Cinsiyete GÃ¶re Boxplot")

# Toplu Ã¶zet
if results_rows:
    st.header("ğŸ§¾ Toplu Ã–zet Tablosu (SeÃ§ili Tetkikler)")
    res_df = pd.DataFrame(results_rows)
    st.dataframe(res_df, use_container_width=True)
    export_df(res_df, name="tetkik_ozet.csv")

# ================= Otomatik Rapor (TÃ¼m Tetkikler) ================= #
st.header("ğŸ“‘ Otomatik Rapor (TÃ¼m Tetkikler)")
if st.button("Raporu Ã¼ret (tam veri)"):
    rows = []
    for t in sorted(df["TETKIK_ISMI"].dropna().astype(str).unique()):
        sub = df[df["TETKIK_ISMI"].astype(str) == t].copy()
        sub["TEST_DEGERI"] = pd.to_numeric(sub["TEST_DEGERI"], errors="coerce")
        sub = sub.dropna(subset=["TEST_DEGERI"])
        if sub.empty:
            continue
        stats_overall = descr_stats_fast(sub["TEST_DEGERI"])
        msg, _ = nonparametric_test_by_group(sub, "TEST_DEGERI", "CINSIYET")
        rows.append({
            "TETKIK_ISMI": t,
            "N": stats_overall["count"],
            "Mean": stats_overall["mean"],
            "Median": stats_overall["median"],
            "Std": stats_overall["std"],
            "Min": stats_overall["min"],
            "Q1": stats_overall["q1"],
            "Q3": stats_overall["q3"],
            "Max": stats_overall["max"],
            "Normalite": normality_flag(sub["TEST_DEGERI"]),
            "Test": msg
        })
    if rows:
        rpt = pd.DataFrame(rows)
        st.success("Rapor hazÄ±rlandÄ±.")
        st.dataframe(rpt, use_container_width=True)
        export_df(rpt, name="tum_tetkikler_rapor.csv")
    else:
        st.warning("Rapor iÃ§in uygun veri bulunamadÄ±.")

st.caption("Performans ipuÃ§larÄ±: Ã‡ok dosya yÃ¼klerken Polars seÃ§eneÄŸini aÃ§Ä±n, grafikleri ihtiyaÃ§ duydukÃ§a gÃ¶sterin, bÃ¼yÃ¼k tablolarÄ± CSV olarak indirip lokal inceleyin.")
'''

with open('app.py', 'w', encoding='utf-8') as f:
    f.write(app_code)

'/mnt/data/app_optimized.py'
# ================= Klinik Tablo (Î²-talasemi tarzÄ±) ================= #
st.header("ğŸ“‹ Klinik Tablo â€” Hematolojik Bulgular (Otomatik)")

src_choice = st.radio(
    "Veri kaynaÄŸÄ±",
    ["SeÃ§imdeki veri (work)", "TÃ¼m veri (df)"],
    index=0,
    horizontal=True
)
base = work.copy() if src_choice.startswith("SeÃ§imdeki") else df.copy()

# Hedef parametreler ve referans aralÄ±klarÄ± (gerekirse dÃ¼zenleyebilirsin)
params = [
    ("Age (years)", None),   # YaÅŸ yoksa otomatik boÅŸ kalÄ±r
    ("Hb (g/dL)", "Hb"),     # (TETKIK_ISMI'ndeki ad)
    ("HCT (%)", "HCT"),
    ("RBC (Ã—10â¶)", "RBC"),
    ("RDW (%)", "RDW"),
    ("MCV (fL)", "MCV"),
    ("MCH (pg)", "MCH"),
    ("MCHC (g/dL)", "MCHC"),
    ("HbA (%)", "HbA"),
    ("HbAâ‚‚ (%)", "HbA2"),
    ("Hb F (%)", "HbF"),
]

ref_ranges = {
    "Hb (g/dL)": "F: 11â€“15; M: 12â€“17",
    "HCT (%)":   "F: 36â€“46; M: 40â€“53",
    "RBC (Ã—10â¶)": "F: 3.9â€“5.6; M: 4.5â€“6.0",
    "RDW (%)":   "11â€“16",
    "MCV (fL)":  "80â€“100",
    "MCH (pg)":  "27â€“34",
    "MCHC (g/dL)": "32â€“36",
    "HbA (%)":   "94â€“98",
    "HbAâ‚‚ (%)":  "2â€“3.5",
    "Hb F (%)":  "0â€“2",
    "Age (years)": "â€”",
}

# Cinsiyet normalizasyonu
sex_map = {
    "e": "Male", "erkek": "Male", "m": "Male", "male": "Male",
    "k": "Female","kadÄ±n":"Female","f":"Female","female":"Female"
}
base["__SEX__"] = (
    base["CINSIYET"].astype(str).str.strip().str.lower().map(sex_map)
)
# TEST_DEGERI sayÄ±sal gÃ¼vence
base["__VAL__"] = pd.to_numeric(
    base["TEST_DEGERI"].astype(str).str.replace(",", ".", regex=False),
    errors="coerce"
)

def fmt_mean_sd(s: pd.Series, nd=2):
    s = pd.to_numeric(s, errors="coerce").dropna()
    if len(s) == 0:
        return "â€”"
    return f"{s.mean():.{nd}f} Â± {s.std(ddof=1):.{nd}f}"

rows = []
for label, tetkik_ismi in params:
    # Age yoksa "â€”" bÄ±rak (datasetinde AGE sÃ¼tunu varsa 'AGE'â†’numeric yapÄ±p buraya entegre edebilirsin)
    if tetkik_ismi is None:
        female = "â€”"
        male = "â€”"
    else:
        sub = base[base["TETKIK_ISMI"].astype(str) == tetkik_ismi].copy()
        female = fmt_mean_sd(sub.loc[sub["__SEX__"]=="Female", "__VAL__"])
        male   = fmt_mean_sd(sub.loc[sub["__SEX__"]=="Male", "__VAL__"])

    rows.append({
        "Parameter": label,
        "Female (Mean Â± SD)": female,
        "Male (Mean Â± SD)": male,
        "Reference range": ref_ranges.get(label, "â€”")
    })

table_df = pd.DataFrame(rows)

# GÃ¶rÃ¼ntÃ¼le + indir
st.dataframe(table_df, use_container_width=True)
csv_bytes = table_df.to_csv(index=False).encode("utf-8-sig")
st.download_button("â¬‡ï¸ Tabloyu CSV indir", data=csv_bytes, file_name="klinik_tablo.csv", mime="text/csv")

st.caption(
    "Not: Cinsiyet eÅŸleÅŸtirmesi E/K/Erkek/KadÄ±n/Male/Female yazÄ±mlarÄ±nÄ± otomatik algÄ±lar. "
    "YaÅŸ (Age) veriniz yoksa satÄ±r 'â€”' kalÄ±r. Ä°stersen AGE/YAÅ sÃ¼tununu eklersen hesaplarÄ±m."
)
